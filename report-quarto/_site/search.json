[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "Relatório\nGustavo Chaves Ferreira - 2022043329\nJúlio Guerra Domingues - 2022431280\n\n\n\nEste relatório apresenta a implementação de um algoritmo de compressão de arquivos utilizando o método Lempel-Ziv-Welch (LZW). O foco principal é demonstrar como estruturas de dados, especificamente a trie compacta, podem ser empregadas para otimizar o processo de compressão e descompressão. Além disso, discutiremos os resultados obtidos a partir de testes realizados com diferentes tipos de arquivos, incluindo textos, imagens e arquivos binários, analisando em quais situações o algoritmo é mais ou menos eficiente.\n\n\n\n\nO algoritmo LZW é um método de compressão sem perdas que substitui sequências repetidas de símbolos por códigos inteiros, reduzindo assim o tamanho total do arquivo. O algoritmo opera construindo um dicionário de sequências de caracteres à medida que percorre o arquivo de entrada. Inicialmente, o dicionário contém todas as possíveis representações de um único símbolo do alfabeto utilizado (no caso, os 256 símbolos da tabela ASCII).\n\n\n\nInicialização: O dicionário é inicializado com todas as sequências de comprimento um possíveis (símbolos ASCII).\n\nLeitura de Símbolos: O algoritmo lê os símbolos de entrada um a um, construindo sequências concatenadas.\n\nVerificação no Dicionário: Se a sequência atual existe no dicionário, o algoritmo continua concatenando o próximo símbolo.\n\nAtualização do Dicionário:\n\nAdiciona a nova sequência ao dicionário com um novo código.\n\nEmite o código correspondente à sequência anterior.\n\nReinicia a sequência com o símbolo atual.\n\n\nAjuste do Tamanho do Código: O algoritmo pode operar com tamanho de código fixo ou variável. Na implementação atual, utilizamos um tamanho de código variável, aumentando o número de bits conforme o dicionário cresce.\n\n\n\n\n\nInicialização: O dicionário é inicializado de forma semelhante à compressão.\n\nLeitura de Códigos: O algoritmo lê os códigos do arquivo comprimido.\n\nReconstrução das Sequências: Com base nos códigos e no dicionário, o algoritmo reconstrói as sequências originais.\n\nAtualização do Dicionário: Novas sequências são adicionadas ao dicionário à medida que são descobertas.\n\n\n\n\n\n\nAs classes CompactTrie e CompactTrieNode formam a estrutura de dados base para gerenciar prefixos binários de forma eficiente. A classe TrieLZW utiliza esta Trie para implementar o algoritmo de compressão LZW, otimizando armazenamento e buscas durante compressão e descompressão.\n\n\n\nLinguagem: Python.\n\nManipulação de Bits: Utilização de strings binárias para representar sequências e códigos.\n\nTamanho do Código: Implementação com tamanho de código variável, iniciando com 9 bits e aumentando conforme o dicionário cresce.\n\nEntrada/Saída: O programa recebe parâmetros via linha de comando, permitindo especificar arquivos de entrada, saída e configurações opcionais.\n\nEstatísticas: Durante a compressão e descompressão, estatísticas como taxa de compressão, tamanho do dicionário, tempo de execução e uso de memória são coletadas.\n\n\n\n\n\n\n\n\nEssa classe representa os nós de uma Trie Compacta Binária.\n- Atributos:\n- children: Uma lista de dois filhos binários (0 ou 1), inicializados como None.\n- binary_string: String binária representando o prefixo associado ao nó.\n- value: Valor armazenado no nó, utilizado para buscas e compressão.\n- is_leaf: Indicador booleano se o nó é uma folha.\n- unique_id: Um identificador único gerado automaticamente para o nó (usado para visualização).\n\n\n\nImplementa uma Trie Compacta Binária, otimizando buscas e inserções baseadas em prefixos binários.\n- Principais Métodos:\n- get_common_prefix_length(key1, key2): Retorna o comprimento do prefixo comum entre duas strings binárias, essencial para dividir ou inserir nós.\n- search(key): Busca um nó na Trie com o exato prefixo igual a key. Retorna o nó encontrado ou None se a chave não existe.\n- insert(key, value): Insere um novo nó com a string binária key e o valor value.\n- delete_key(key): Remove uma chave key da Trie.\n- visualize(filename): Gera uma visualização da Trie em formato gráfico (.png) utilizando o graphviz, para debug. Cada nó é rotulado com seu prefixo e, caso seja folha, o valor associado.\n\n\n\nImplementa o algoritmo LZW, utilizando uma Trie Compacta Binária como dicionário dinâmico.\n- Principais Métodos:\n- compress(file_path, compression_type, codes_max_size): Aplica a compressão LZW em um arquivo de entrada. Lida com os diferentes tipos de compressão (estática e dinâmica). O arquivo comprimido é salvo em formato binário (.bin), com cabeçalho indicando o tamanho do padding utilizado.\n- decompress(file_path, compression_type, original_file_name, original_file_extension, codes_max_size): Restaura o arquivo original a partir de um arquivo comprimido. Reconstrói os símbolos originais com base nos códigos comprimidos. Gerencia expansão ou reset do dicionário conforme o tipo de compressão. O arquivo descomprimido é salvo com a extensão original.\n\n\n\n\n\n\n\n\nInicializa um dicionário com todas as combinações ASCII.\n\nLê o arquivo original byte a byte, criando sequências de símbolos.\n\nPara cada nova sequência:\n\nSe a sequência estiver no dicionário, continua adicionando símbolos.\n\nCaso contrário, adiciona a sequência ao dicionário com um novo código.\n\n\nSalva os códigos resultantes em um arquivo binário comprimido.\n\n\n\n\n\nInicializa um dicionário idêntico ao da compressão.\n\nLê os códigos do arquivo comprimido e busca as sequências correspondentes no dicionário.\n\nAdiciona novas sequências ao dicionário conforme os códigos são interpretados.\n\nReconstrói o conteúdo original e o salva no formato correspondente.\n\n\n\n\n\n\n\n\npython3 lzw.py compress &lt;arquivo_a_ser_comprimido.*&gt; &lt;arquivo_comprimido.bin&gt; --stats-file &lt;arquivo_com_estatisticas.json&gt;\n\n\n\ncompress: Indica que o programa realizará a compressão do arquivo.\n\n&lt;arquivo_a_ser_comprimido.*&gt;: Caminho do arquivo de entrada que será comprimido.\n\n&lt;arquivo_comprimido.bin&gt;: Caminho onde o arquivo comprimido será salvo.\n\n--stats-file &lt;arquivo_com_estatisticas.json&gt;: (Opcional) Especifica o arquivo JSON onde as estatísticas da compressão, como tamanho inicial e comprimido, serão salvas.\n\n\n\n\n\npython3 lzw.py decompress &lt;arquivo_comprimido.bin&gt; &lt;arquivo_descomprimido.*&gt; --max-bits &lt;&gt; --stats-file &lt;arquivo_com_estatísticas.json&gt;\n\n\n\ndecompress: Indica que o programa realizará a descompressão do arquivo.\n\n&lt;arquivo_a_ser_descomprimido.bin&gt;: Caminho do arquivo comprimido que será descomprimido.\n\n&lt;arquivo_descomprimido.*&gt;: Caminho onde o arquivo descomprimido será salvo.\n\n--max-bits &lt;&gt;: Define o tamanho máximo dos códigos (em bits) utilizados na descompressão.\n\n--stats-file &lt;arquivo_com_estatísticas.json&gt;: (Opcional) Especifica o arquivo JSON onde as estatísticas da descompressão, como tamanho do arquivo comprimido e descomprimido, serão salvas.\n\n\n\n\n\n\n\n\nO código foi instrumentado para monitorar os tempos de compressão e descompressão, razão de compressão, tamanho do dicionário e uso de memória. Para cada arquivo descomprimido, foi verificada a integridade a partir da comparação binária, para assegurar que os dados originais foram recuperados sem perdas.\nTais variáveis foram avaliadas em arquivos de diferentes tipos e tamanhos, de forma a verificar o desempenho do algoritmo em diferentes cenários. Foram realizados testes com arquivos de texto (.txt), imagem (.bmp, .pgm), áudio (.wav) e binários (.bin). Outros formatos comuns de arquivos, como .jpg, .png e .mpg, não foram testados pois já apresentam compressão (com ou sem perdas), o que influenciaria no comportamento do programa e prejudicaria as análises.\n\n\n\n\n\nA eficiência do algoritmo LZW é altamente dependente das características dos dados de entrada. A seguir, discutimos como diferentes fatores influenciam a taxa de compressão em textos, imagens e arquivos binários. A respeito das duas variantes do algoritmo, a versão dinâmica se demonstrou mais atrativa do que sua variável estática nos momentos em que os limites para tamanho de código máximo não ultrapassaram a faixa de 16 a 20 bits. O uso de tamanhos de códigos variáveis associados a uma escolha ponderada de um teto de crescimento apresentaram melhores taxas de compressão em comparação à alternativa de sempre emitir códigos de 12 bits para a maioria dos casos. Vale ressaltar que o uso de memória pode se tornar um problema caso o dicionário representado pela árvore de prefixos cresça de forma preponderante. Ademais, códigos muito extensos tendem a anular o efeito da compressão para execuções muito longas. Para se ter uma ideia do desempenho do LZW para os casos principais de texto (‘.txt’) e de imagem (‘.bmp’), o algoritmo no caso estático teve os seguintes resultados:\nO arquivo de texto “test_text.txt” com 200 mil caracteres apresentou uma redução de 200000 bytes para 59537 bytes. A imagem “imagemhomog_30kb.bmp” de tamanho inicial 282062 bytes se reduziu para 3417 bytes (a redundância foi bem aproveitada).\nPara formatos de arquivo mais variados, algumas estatísticas obtidas estão representadas abaixo. Elas são seguidas por comentários a respeito de cada formato.\n\n\nCompressão:\nDescompressão:\n\n\n\n\n\n\nTextos com muitas repetições, como documentos com vocabulário limitado ou formatos estruturados (como XML ou JSON), tendem a ser mais compressíveis. Isso ocorre porque o LZW aproveita sequências repetidas para construir um dicionário mais eficiente. Textos ricos em vocabulário, como obras literárias, têm menos repetições e, portanto, menor taxa de compressão.\n\n\n\nImagens com áreas grandes de cor uniforme, como gráficos ou desenhos animados, são mais compressíveis. Já imagens fotográficas, com variação de cores e detalhes finos, oferecem menos oportunidades para compressão. Imagens em escala de cinza ou monocromáticas têm menos informações por pixel do que imagens coloridas, resultando em maior taxa de compressão. Imagens já comprimidas em formatos como JPEG ou PNG (que usam compressão com perdas e sem perdas, respectivamente) podem não ser eficazmente comprimidas novamente pelo LZW.\n\n\n\nA compressão de arquivos WAV utilizando o algoritmo LZW é influenciada principalmente pela redundância dos dados de áudio, parâmetros de gravação como taxa de amostragem e profundidade de bits, complexidade do conteúdo de áudio, e configurações do algoritmo LZW. Arquivos WAV com alta redundância e padrões repetitivos são mais eficazmente comprimidos pelo LZW, enquanto aqueles com alta entropia e variações rápidas apresentarão menores taxas de compressão.\n\n\n\nArquivos binários com dados aleatórios ou já comprimidos (como arquivos ZIP ou executáveis) possuem alta entropia, o que torna a compressão adicional ineficiente. Se o arquivo binário contém estruturas repetitivas ou padrões previsíveis, o LZW pode obter alguma compressão. Arquivos binários que representam dados estruturados (por exemplo, registros com campos fixos) podem ser mais suscetíveis à compressão.\n\n\n\nObserva-se que a taxa de compressão tende a estabilizar conforme o dicionário cresce e o algoritmo encontra sequências repetidas mais longas. Em arquivos com alta redundância, a taxa de compressão inicial é mais acentuada. O crescimento do dicionário é mais rápido em arquivos com muitos padrões únicos, o que pode afetar o desempenho em termos de memória.\n\n\n\n\n\n\nA implementação do algoritmo LZW utilizando uma trie compacta demonstrou-se eficaz na compressão de arquivos de diferentes tipos. A estrutura de dados escolhida permitiu otimizar as operações críticas do algoritmo, resultando em tempos de execução aceitáveis e uso de memória controlado. Os testes realizados confirmaram a correta funcionalidade do algoritmo, preservando a integridade dos dados após a compressão e descompressão. Observou-se que a eficiência da compressão varia conforme o tipo de arquivo e suas características intrínsecas, sendo mais eficaz em dados com alta redundância. Enquanto métodos como o LZW oferecem uma base sólida e flexibilidade, o avanço contínuo na tecnologia de compressão tem permitido o desenvolvimento de soluções mais especializadas e eficientes para domínios específicos. Assim, a escolha informada do método de compressão não apenas maximiza a eficiência do armazenamento, mas também preserva a integridade e qualidade dos dados de maneira mais eficaz.\n\n\n\n\n\nLempel A, Ziv J. Compression of Individual Sequences via Variable-Rate Coding. IEEE Transactions on Information Theory, 1978.\n\nCS Sound Files\n\nMIT Lecture Notes\n\nDavid Salomon - Data Compression\n\n\n\n\n\n\nCódigo Fonte: Disponível no GitHub.\n\nEstatísticas Detalhadas: Os arquivos utilizados nos testes e JSON com dados completos das execuções estão disponíveis na pasta /tests."
  },
  {
    "objectID": "index.html#introdução",
    "href": "index.html#introdução",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "Este relatório apresenta a implementação de um algoritmo de compressão de arquivos utilizando o método Lempel-Ziv-Welch (LZW). O foco principal é demonstrar como estruturas de dados, especificamente a trie compacta, podem ser empregadas para otimizar o processo de compressão e descompressão. Além disso, discutiremos os resultados obtidos a partir de testes realizados com diferentes tipos de arquivos, incluindo textos, imagens e arquivos binários, analisando em quais situações o algoritmo é mais ou menos eficiente."
  },
  {
    "objectID": "index.html#descrição-do-algoritmo-lzw",
    "href": "index.html#descrição-do-algoritmo-lzw",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "O algoritmo LZW é um método de compressão sem perdas que substitui sequências repetidas de símbolos por códigos inteiros, reduzindo assim o tamanho total do arquivo. O algoritmo opera construindo um dicionário de sequências de caracteres à medida que percorre o arquivo de entrada. Inicialmente, o dicionário contém todas as possíveis representações de um único símbolo do alfabeto utilizado (no caso, os 256 símbolos da tabela ASCII).\n\n\n\nInicialização: O dicionário é inicializado com todas as sequências de comprimento um possíveis (símbolos ASCII).\n\nLeitura de Símbolos: O algoritmo lê os símbolos de entrada um a um, construindo sequências concatenadas.\n\nVerificação no Dicionário: Se a sequência atual existe no dicionário, o algoritmo continua concatenando o próximo símbolo.\n\nAtualização do Dicionário:\n\nAdiciona a nova sequência ao dicionário com um novo código.\n\nEmite o código correspondente à sequência anterior.\n\nReinicia a sequência com o símbolo atual.\n\n\nAjuste do Tamanho do Código: O algoritmo pode operar com tamanho de código fixo ou variável. Na implementação atual, utilizamos um tamanho de código variável, aumentando o número de bits conforme o dicionário cresce.\n\n\n\n\n\nInicialização: O dicionário é inicializado de forma semelhante à compressão.\n\nLeitura de Códigos: O algoritmo lê os códigos do arquivo comprimido.\n\nReconstrução das Sequências: Com base nos códigos e no dicionário, o algoritmo reconstrói as sequências originais.\n\nAtualização do Dicionário: Novas sequências são adicionadas ao dicionário à medida que são descobertas."
  },
  {
    "objectID": "index.html#implementação",
    "href": "index.html#implementação",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "As classes CompactTrie e CompactTrieNode formam a estrutura de dados base para gerenciar prefixos binários de forma eficiente. A classe TrieLZW utiliza esta Trie para implementar o algoritmo de compressão LZW, otimizando armazenamento e buscas durante compressão e descompressão.\n\n\n\nLinguagem: Python.\n\nManipulação de Bits: Utilização de strings binárias para representar sequências e códigos.\n\nTamanho do Código: Implementação com tamanho de código variável, iniciando com 9 bits e aumentando conforme o dicionário cresce.\n\nEntrada/Saída: O programa recebe parâmetros via linha de comando, permitindo especificar arquivos de entrada, saída e configurações opcionais.\n\nEstatísticas: Durante a compressão e descompressão, estatísticas como taxa de compressão, tamanho do dicionário, tempo de execução e uso de memória são coletadas."
  },
  {
    "objectID": "index.html#principais-classes",
    "href": "index.html#principais-classes",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "Essa classe representa os nós de uma Trie Compacta Binária.\n- Atributos:\n- children: Uma lista de dois filhos binários (0 ou 1), inicializados como None.\n- binary_string: String binária representando o prefixo associado ao nó.\n- value: Valor armazenado no nó, utilizado para buscas e compressão.\n- is_leaf: Indicador booleano se o nó é uma folha.\n- unique_id: Um identificador único gerado automaticamente para o nó (usado para visualização).\n\n\n\nImplementa uma Trie Compacta Binária, otimizando buscas e inserções baseadas em prefixos binários.\n- Principais Métodos:\n- get_common_prefix_length(key1, key2): Retorna o comprimento do prefixo comum entre duas strings binárias, essencial para dividir ou inserir nós.\n- search(key): Busca um nó na Trie com o exato prefixo igual a key. Retorna o nó encontrado ou None se a chave não existe.\n- insert(key, value): Insere um novo nó com a string binária key e o valor value.\n- delete_key(key): Remove uma chave key da Trie.\n- visualize(filename): Gera uma visualização da Trie em formato gráfico (.png) utilizando o graphviz, para debug. Cada nó é rotulado com seu prefixo e, caso seja folha, o valor associado.\n\n\n\nImplementa o algoritmo LZW, utilizando uma Trie Compacta Binária como dicionário dinâmico.\n- Principais Métodos:\n- compress(file_path, compression_type, codes_max_size): Aplica a compressão LZW em um arquivo de entrada. Lida com os diferentes tipos de compressão (estática e dinâmica). O arquivo comprimido é salvo em formato binário (.bin), com cabeçalho indicando o tamanho do padding utilizado.\n- decompress(file_path, compression_type, original_file_name, original_file_extension, codes_max_size): Restaura o arquivo original a partir de um arquivo comprimido. Reconstrói os símbolos originais com base nos códigos comprimidos. Gerencia expansão ou reset do dicionário conforme o tipo de compressão. O arquivo descomprimido é salvo com a extensão original."
  },
  {
    "objectID": "index.html#fluxo-do-algoritmo-lzw",
    "href": "index.html#fluxo-do-algoritmo-lzw",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "Inicializa um dicionário com todas as combinações ASCII.\n\nLê o arquivo original byte a byte, criando sequências de símbolos.\n\nPara cada nova sequência:\n\nSe a sequência estiver no dicionário, continua adicionando símbolos.\n\nCaso contrário, adiciona a sequência ao dicionário com um novo código.\n\n\nSalva os códigos resultantes em um arquivo binário comprimido.\n\n\n\n\n\nInicializa um dicionário idêntico ao da compressão.\n\nLê os códigos do arquivo comprimido e busca as sequências correspondentes no dicionário.\n\nAdiciona novas sequências ao dicionário conforme os códigos são interpretados.\n\nReconstrói o conteúdo original e o salva no formato correspondente."
  },
  {
    "objectID": "index.html#execução",
    "href": "index.html#execução",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "python3 lzw.py compress &lt;arquivo_a_ser_comprimido.*&gt; &lt;arquivo_comprimido.bin&gt; --stats-file &lt;arquivo_com_estatisticas.json&gt;\n\n\n\ncompress: Indica que o programa realizará a compressão do arquivo.\n\n&lt;arquivo_a_ser_comprimido.*&gt;: Caminho do arquivo de entrada que será comprimido.\n\n&lt;arquivo_comprimido.bin&gt;: Caminho onde o arquivo comprimido será salvo.\n\n--stats-file &lt;arquivo_com_estatisticas.json&gt;: (Opcional) Especifica o arquivo JSON onde as estatísticas da compressão, como tamanho inicial e comprimido, serão salvas.\n\n\n\n\n\npython3 lzw.py decompress &lt;arquivo_comprimido.bin&gt; &lt;arquivo_descomprimido.*&gt; --max-bits &lt;&gt; --stats-file &lt;arquivo_com_estatísticas.json&gt;\n\n\n\ndecompress: Indica que o programa realizará a descompressão do arquivo.\n\n&lt;arquivo_a_ser_descomprimido.bin&gt;: Caminho do arquivo comprimido que será descomprimido.\n\n&lt;arquivo_descomprimido.*&gt;: Caminho onde o arquivo descomprimido será salvo.\n\n--max-bits &lt;&gt;: Define o tamanho máximo dos códigos (em bits) utilizados na descompressão.\n\n--stats-file &lt;arquivo_com_estatísticas.json&gt;: (Opcional) Especifica o arquivo JSON onde as estatísticas da descompressão, como tamanho do arquivo comprimido e descomprimido, serão salvas."
  },
  {
    "objectID": "index.html#testes",
    "href": "index.html#testes",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "O código foi instrumentado para monitorar os tempos de compressão e descompressão, razão de compressão, tamanho do dicionário e uso de memória. Para cada arquivo descomprimido, foi verificada a integridade a partir da comparação binária, para assegurar que os dados originais foram recuperados sem perdas.\nTais variáveis foram avaliadas em arquivos de diferentes tipos e tamanhos, de forma a verificar o desempenho do algoritmo em diferentes cenários. Foram realizados testes com arquivos de texto (.txt), imagem (.bmp, .pgm), áudio (.wav) e binários (.bin). Outros formatos comuns de arquivos, como .jpg, .png e .mpg, não foram testados pois já apresentam compressão (com ou sem perdas), o que influenciaria no comportamento do programa e prejudicaria as análises."
  },
  {
    "objectID": "index.html#resultados-e-discussão",
    "href": "index.html#resultados-e-discussão",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "A eficiência do algoritmo LZW é altamente dependente das características dos dados de entrada. A seguir, discutimos como diferentes fatores influenciam a taxa de compressão em textos, imagens e arquivos binários. A respeito das duas variantes do algoritmo, a versão dinâmica se demonstrou mais atrativa do que sua variável estática nos momentos em que os limites para tamanho de código máximo não ultrapassaram a faixa de 16 a 20 bits. O uso de tamanhos de códigos variáveis associados a uma escolha ponderada de um teto de crescimento apresentaram melhores taxas de compressão em comparação à alternativa de sempre emitir códigos de 12 bits para a maioria dos casos. Vale ressaltar que o uso de memória pode se tornar um problema caso o dicionário representado pela árvore de prefixos cresça de forma preponderante. Ademais, códigos muito extensos tendem a anular o efeito da compressão para execuções muito longas. Para se ter uma ideia do desempenho do LZW para os casos principais de texto (‘.txt’) e de imagem (‘.bmp’), o algoritmo no caso estático teve os seguintes resultados:\nO arquivo de texto “test_text.txt” com 200 mil caracteres apresentou uma redução de 200000 bytes para 59537 bytes. A imagem “imagemhomog_30kb.bmp” de tamanho inicial 282062 bytes se reduziu para 3417 bytes (a redundância foi bem aproveitada).\nPara formatos de arquivo mais variados, algumas estatísticas obtidas estão representadas abaixo. Elas são seguidas por comentários a respeito de cada formato.\n\n\nCompressão:\nDescompressão:\n\n\n\n\n\n\nTextos com muitas repetições, como documentos com vocabulário limitado ou formatos estruturados (como XML ou JSON), tendem a ser mais compressíveis. Isso ocorre porque o LZW aproveita sequências repetidas para construir um dicionário mais eficiente. Textos ricos em vocabulário, como obras literárias, têm menos repetições e, portanto, menor taxa de compressão.\n\n\n\nImagens com áreas grandes de cor uniforme, como gráficos ou desenhos animados, são mais compressíveis. Já imagens fotográficas, com variação de cores e detalhes finos, oferecem menos oportunidades para compressão. Imagens em escala de cinza ou monocromáticas têm menos informações por pixel do que imagens coloridas, resultando em maior taxa de compressão. Imagens já comprimidas em formatos como JPEG ou PNG (que usam compressão com perdas e sem perdas, respectivamente) podem não ser eficazmente comprimidas novamente pelo LZW.\n\n\n\nA compressão de arquivos WAV utilizando o algoritmo LZW é influenciada principalmente pela redundância dos dados de áudio, parâmetros de gravação como taxa de amostragem e profundidade de bits, complexidade do conteúdo de áudio, e configurações do algoritmo LZW. Arquivos WAV com alta redundância e padrões repetitivos são mais eficazmente comprimidos pelo LZW, enquanto aqueles com alta entropia e variações rápidas apresentarão menores taxas de compressão.\n\n\n\nArquivos binários com dados aleatórios ou já comprimidos (como arquivos ZIP ou executáveis) possuem alta entropia, o que torna a compressão adicional ineficiente. Se o arquivo binário contém estruturas repetitivas ou padrões previsíveis, o LZW pode obter alguma compressão. Arquivos binários que representam dados estruturados (por exemplo, registros com campos fixos) podem ser mais suscetíveis à compressão.\n\n\n\nObserva-se que a taxa de compressão tende a estabilizar conforme o dicionário cresce e o algoritmo encontra sequências repetidas mais longas. Em arquivos com alta redundância, a taxa de compressão inicial é mais acentuada. O crescimento do dicionário é mais rápido em arquivos com muitos padrões únicos, o que pode afetar o desempenho em termos de memória."
  },
  {
    "objectID": "index.html#conclusão",
    "href": "index.html#conclusão",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "A implementação do algoritmo LZW utilizando uma trie compacta demonstrou-se eficaz na compressão de arquivos de diferentes tipos. A estrutura de dados escolhida permitiu otimizar as operações críticas do algoritmo, resultando em tempos de execução aceitáveis e uso de memória controlado. Os testes realizados confirmaram a correta funcionalidade do algoritmo, preservando a integridade dos dados após a compressão e descompressão. Observou-se que a eficiência da compressão varia conforme o tipo de arquivo e suas características intrínsecas, sendo mais eficaz em dados com alta redundância. Enquanto métodos como o LZW oferecem uma base sólida e flexibilidade, o avanço contínuo na tecnologia de compressão tem permitido o desenvolvimento de soluções mais especializadas e eficientes para domínios específicos. Assim, a escolha informada do método de compressão não apenas maximiza a eficiência do armazenamento, mas também preserva a integridade e qualidade dos dados de maneira mais eficaz."
  },
  {
    "objectID": "index.html#referências",
    "href": "index.html#referências",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "Lempel A, Ziv J. Compression of Individual Sequences via Variable-Rate Coding. IEEE Transactions on Information Theory, 1978.\n\nCS Sound Files\n\nMIT Lecture Notes\n\nDavid Salomon - Data Compression"
  },
  {
    "objectID": "index.html#anexos",
    "href": "index.html#anexos",
    "title": "Relatório de Compressão e Descompressão com LZW",
    "section": "",
    "text": "Código Fonte: Disponível no GitHub.\n\nEstatísticas Detalhadas: Os arquivos utilizados nos testes e JSON com dados completos das execuções estão disponíveis na pasta /tests."
  }
]