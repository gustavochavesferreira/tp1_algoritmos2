{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QdirNd4QFY_B",
        "tPUXHOt-Fg46",
        "1xCgIMdnIFn2",
        "j1DNUBiQFIEK",
        "DmRmH2ByF57b",
        "W0AHGnxlDQKE"
      ],
      "authorship_tag": "ABX9TyMkltnyPNU3NmNglkIflKZY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d145359c4f9e4658ae6618ddb61020a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Auto",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ed212259f21a4803a759441455449ddd",
            "style": "IPY_MODEL_24b80722b0fb4a5aa6fb9354b4481496",
            "tooltip": ""
          }
        },
        "ed212259f21a4803a759441455449ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b80722b0fb4a5aa6fb9354b4481496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustavochavesferreira/tp1_algoritmos2/blob/main/LZW_implementation_last_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Instalações provisórias para debug"
      ],
      "metadata": {
        "id": "QdirNd4QFY_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz\n",
        "!apt-get install graphviz -y\n",
        "\n",
        "from graphviz import Digraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frdzrsj6KUqW",
        "outputId": "406d1ab9-6a01-4b21-b7b8-6f1874f72806"
      },
      "execution_count": 1113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação da árvore de prefixos (Trie)"
      ],
      "metadata": {
        "id": "tPUXHOt-Fg46"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1114,
      "metadata": {
        "id": "jxrMRlgpVFe_"
      },
      "outputs": [],
      "source": [
        "from pickle import FALSE\n",
        "class CompactTrieNode:\n",
        "  def __init__(self, binary_string: str = \"\", value: str = \"\", is_leaf: bool = False) -> None:\n",
        "    self.children = [None, None]\n",
        "    self.is_leaf = is_leaf\n",
        "    self.binary_string = binary_string\n",
        "    self.value = value\n",
        "    self.unique_id = id(self)  # Temporário\n",
        "\n",
        "class CompactTrie:\n",
        "  def __init__(self) -> None:\n",
        "    self.root = None\n",
        "\n",
        "  def get_common_prefix_length(self, key1: str, key2: str) -> int:\n",
        "    i = 0\n",
        "    while i < min(len(key1), len(key2)) and key1[i] == key2[i]:\n",
        "        i += 1\n",
        "    return i\n",
        "\n",
        "  def search(self, key: str) -> CompactTrieNode:\n",
        "    current_node = self.root\n",
        "\n",
        "    if(current_node == None):\n",
        "      return None\n",
        "\n",
        "    while True:\n",
        "\n",
        "      if(current_node.binary_string == key):\n",
        "        if(current_node.is_leaf == True):\n",
        "          return current_node\n",
        "        else:\n",
        "          return None\n",
        "\n",
        "      common_prefix_length = self.get_common_prefix_length(current_node.binary_string, key)\n",
        "\n",
        "      if(common_prefix_length == len(current_node.binary_string)):\n",
        "\n",
        "        key = key[common_prefix_length:]\n",
        "\n",
        "        if current_node.children[int(key[0])] == None:\n",
        "          return None\n",
        "\n",
        "        current_node = current_node.children[int(key[0])]\n",
        "      else:\n",
        "        return None\n",
        "\n",
        "  def insert(self, key: str, value: str) -> None:\n",
        "    # Caso em que não tínhamos raiz\n",
        "    if(self.root == None):\n",
        "      self.root = CompactTrieNode(key, value, True)\n",
        "      return\n",
        "\n",
        "    else:\n",
        "      current_node = self.root\n",
        "\n",
        "      while True:\n",
        "        # Achei, posso parar\n",
        "        if(current_node.binary_string == key):\n",
        "          current_node.is_leaf = True\n",
        "          return\n",
        "\n",
        "        common_prefix_length = self.get_common_prefix_length(current_node.binary_string, key)\n",
        "\n",
        "        # Sobrou parte da key ainda, com certeza\n",
        "        if (common_prefix_length == len(current_node.binary_string)):\n",
        "          key = key[common_prefix_length:]\n",
        "\n",
        "          if current_node.children[int(key[0])] == None:\n",
        "            current_node.children[int(key[0])] = CompactTrieNode(key, value, True)\n",
        "            return\n",
        "\n",
        "          current_node = current_node.children[int(key[0])]\n",
        "\n",
        "        # Achei onde vou ter que criar novo nó para inserir\n",
        "        else:\n",
        "          key = key[common_prefix_length:]\n",
        "\n",
        "          if(current_node.is_leaf == True):\n",
        "            old_suffix_node = CompactTrieNode(current_node.binary_string[common_prefix_length:], current_node.value, True)\n",
        "          else:\n",
        "            old_suffix_node = CompactTrieNode(current_node.binary_string[common_prefix_length:], current_node.value)\n",
        "\n",
        "          old_suffix_node.children[0] = current_node.children[0]\n",
        "          old_suffix_node.children[1] = current_node.children[1]\n",
        "\n",
        "          current_node.binary_string = current_node.binary_string[:common_prefix_length]\n",
        "\n",
        "          if(len(key) > 0):\n",
        "            key_suffix_node = CompactTrieNode(key, value, True)\n",
        "            current_node.is_leaf = False\n",
        "            current_node.children[int(key_suffix_node.binary_string[0])] = key_suffix_node\n",
        "            current_node.children[int(old_suffix_node.binary_string[0])] = old_suffix_node\n",
        "          else:\n",
        "            current_node.value = value\n",
        "            current_node.is_leaf = True\n",
        "            current_node.children = [None, None]\n",
        "            current_node.children[int(old_suffix_node.binary_string[0])] = old_suffix_node\n",
        "          return\n",
        "\n",
        "  def delete_key(self, key: str) -> None:\n",
        "    if(self.search(key) == None):\n",
        "      return\n",
        "\n",
        "    current_node = self.root\n",
        "    last_node = self.root\n",
        "\n",
        "    if(current_node.binary_string == key):\n",
        "      if(current_node.children[0] == None and current_node.children[1] == None):\n",
        "        self.root = None\n",
        "        return\n",
        "      elif(current_node.children[0] != None and current_node.children[1] != None):\n",
        "        current_node.is_leaf = False\n",
        "        return\n",
        "      else:\n",
        "        valid_child = 0 if current_node.children[0] != None else 1\n",
        "        current_node.children[valid_child].binary_string = current_node.binary_string + current_node.children[valid_child].binary_string\n",
        "        self.root = current_node.children[valid_child]\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "      if((current_node.binary_string == key) and (current_node.is_leaf == True)):\n",
        "        if((current_node.children[0] != None) and (current_node.children[1] != None)):\n",
        "          current_node.is_leaf = False\n",
        "        elif((current_node.children[0] == None) and (current_node.children[1] == None)):\n",
        "          last_node.children[int(current_node.binary_string[0])] = None\n",
        "\n",
        "          if(last_node.is_leaf == False):\n",
        "            last_node_other_child = 0 if current_node.binary_string[0] == '1' else 1\n",
        "\n",
        "            if(last_node.children[last_node_other_child] != None):\n",
        "              last_node.binary_string += last_node.children[last_node_other_child].binary_string\n",
        "              last_node.value = last_node.children[last_node_other_child].value\n",
        "              if(last_node.children[last_node_other_child].is_leaf):\n",
        "                last_node.is_leaf = True\n",
        "              last_node.children = last_node.children[last_node_other_child].children\n",
        "        else:\n",
        "          valid_child = 0 if current_node.children[0] != None else 1\n",
        "          current_node.children[valid_child].binary_string = current_node.binary_string + current_node.children[valid_child].binary_string\n",
        "          last_node.children[int(current_node.children[valid_child].binary_string[0])] = current_node.children[valid_child]\n",
        "        return\n",
        "\n",
        "      common_prefix_length = self.get_common_prefix_length(current_node.binary_string, key)\n",
        "      key = key[common_prefix_length:]\n",
        "      last_node = current_node\n",
        "      current_node = current_node.children[int(key[0])]\n",
        "\n",
        "  # Temporário\n",
        "  def visualize(self, filename=\"compact_trie\"):\n",
        "      dot = Digraph(comment=\"Compact Trie\")\n",
        "\n",
        "      def add_nodes_edges(node, parent_label=None):\n",
        "          if node is None:\n",
        "              return\n",
        "\n",
        "          new_node_binary_string = node.binary_string\n",
        "          new_node_binary_string = new_node_binary_string.replace(\"0\", \"a\")\n",
        "          new_node_binary_string = new_node_binary_string.replace(\"1\", \"b\")\n",
        "\n",
        "          node_label = f\"{new_node_binary_string}_{node.unique_id}\"\n",
        "\n",
        "          display_label = f\"{new_node_binary_string}\"\n",
        "          if(node.is_leaf):\n",
        "            display_label  += f\"\\\\nValue: {node.value}\"\n",
        "\n",
        "          dot.node(node_label, display_label, shape='circle', color='black', fontcolor='red' if node.is_leaf else 'blue')\n",
        "\n",
        "          if parent_label:\n",
        "              dot.edge(parent_label, node_label)\n",
        "          if node.children[0] is not None:\n",
        "              add_nodes_edges(node.children[0], node_label)\n",
        "          if node.children[1] is not None:\n",
        "              add_nodes_edges(node.children[1], node_label)\n",
        "\n",
        "      if self.root is not None:\n",
        "          add_nodes_edges(self.root)\n",
        "\n",
        "      dot.render(filename, format=\"png\", cleanup=True)\n",
        "      print(f\"Compact trie saved as {filename}.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementando a versão final da compressão LZW, empregando árvores Trie como dicionários para consulta e inserção:"
      ],
      "metadata": {
        "id": "7Eg8GeDbe6xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "from typing import Tuple\n",
        "import struct\n",
        "\n",
        "# Para debug\n",
        "def binary_to_chars(binary_string):\n",
        "    # Ensure the binary string length is a multiple of 8 (since each character is 8 bits)\n",
        "    if len(binary_string) % 8 != 0:\n",
        "        raise ValueError(\"Binary string length must be a multiple of 8.\")\n",
        "\n",
        "    # Split the binary string into chunks of 8 bits\n",
        "    chars = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\n",
        "\n",
        "    # Convert each 8-bit binary chunk to its corresponding character\n",
        "    result = ''.join(chr(int(char, 2)) for char in chars)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Função para converter um conjunto de bytes em um '.txt'\n",
        "def write_txt_file(decoded_bytes, output_file):\n",
        "    decoded_string = ''.join([chr(byte) for byte in decoded_bytes])\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(decoded_string)\n",
        "\n",
        "# Função para converter um conjunto de bytes em um '.bmp' ou '.tiff'\n",
        "def write_image_file(decoded_bytes, output_file):\n",
        "    with open(output_file, 'wb') as file:\n",
        "        file.write(bytes(decoded_bytes))\n",
        "\n",
        "# Função para remover zeros à esquerda em uma string binárias\n",
        "def remove_leading_zeros(binary_str):\n",
        "  return binary_str.lstrip('0') or '0'\n",
        "\n",
        "class TrieLZW:\n",
        "  # Realiza a compressão LZW do arquivo passado como parâmetro\n",
        "  def compress(self, file_path: str=\"\") -> Tuple[str, str]:\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 00000000 até 11111111 no dicionário, com respectivos valores sendo a própria chave\n",
        "    for num in range(256):\n",
        "      byte_num = format(num, '08b')\n",
        "      dictionary.insert(byte_num, byte_num)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\n",
        "    num_bits_values = 9 # Começaremos usando 9 bits para representar códigos a partir de agora\n",
        "    next_dict_size_limit = 2 * 256 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\n",
        "\n",
        "    # Inicializando variáveis utilizadas pela compressão LZW\n",
        "    string = \"\"\n",
        "    compressed_data = []\n",
        "\n",
        "    # Aplicando a compressão LZW, considerando cada byte do arquivo orignal como um símbolo de entrada\n",
        "    try:\n",
        "      count = 256\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        while (byte := file.read(1)):\n",
        "          symbol = bin(int.from_bytes(byte, \"big\"))[2:].zfill(8)\n",
        "\n",
        "          string_plus_symbol = string + symbol\n",
        "\n",
        "          if dictionary.search(string_plus_symbol) != None:\n",
        "              string = string_plus_symbol\n",
        "          else:\n",
        "            # Caso em que o dicionário tem tamanho dinâmico\n",
        "            if(dict_size == next_dict_size_limit):\n",
        "                num_bits_values += 1\n",
        "                next_dict_size_limit *= 2\n",
        "\n",
        "            current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "            compressed_data.append(current_string_formatted_binary_value)\n",
        "            new_key_value = bin(dict_size)[2:].zfill(num_bits_values)\n",
        "            dictionary.insert(string_plus_symbol, new_key_value)\n",
        "            dict_size += 1\n",
        "            string = symbol\n",
        "\n",
        "        if(dictionary.search(string) != None):\n",
        "          current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "          compressed_data.append(current_string_formatted_binary_value)\n",
        "\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError as e:\n",
        "      print(f\"Arquivo não encontrado -> {e}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Erro de I/O -> {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Um erro ocorreu: {e}\")\n",
        "\n",
        "    # Salvando o nome do arquivo original e sua extensão para que o arquivo de compressão possa ser salvo\n",
        "    file_name, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "    with open(f\"compressed_{file_name}.bin\", \"wb\") as file:\n",
        "      # Convertendo os códigos para uma única string\n",
        "      final_concat_string_data = ''.join(compressed_data)\n",
        "\n",
        "      # Verificando se algum padding deverá ser adicionado para que tenhamos um número inteiro de bytes no arquivo comprimido\n",
        "      padding_size = (8 - len(final_concat_string_data) % 8) % 8\n",
        "      final_concat_string_data = '0' * padding_size + final_concat_string_data\n",
        "\n",
        "      # Adicionando uma flag, no arquivo comprimido, para representar o tamanho do padding que foi adicionado\n",
        "      file.write(bytes([padding_size]))\n",
        "\n",
        "      # Convertendo a string de dados comprimidos para bytes e escrevendo no arquivo comprimido final\n",
        "      bits = []\n",
        "      for char in final_concat_string_data:\n",
        "        bits.append(1 if char == '1' else 0)\n",
        "      byte = 0\n",
        "      bit_count = 0\n",
        "      for bit in bits:\n",
        "        byte = (byte << 1) | bit\n",
        "        bit_count += 1\n",
        "        if bit_count == 8:\n",
        "          file.write(bytes([byte]))\n",
        "          byte = 0\n",
        "          bit_count = 0\n",
        "\n",
        "      return [file_name, file_extension]\n",
        "\n",
        "  # Realiza a descompressão LZW do arquivo passado como parâmetro\n",
        "  def decompress(self, file_path: str=\"\", original_file_name: str=\"\", original_file_extension: str=\"\") -> None:\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 0, 1, 10, 11, 100, ... até 11111111 no dicionário (sem padding), com respectivos valores sendo a própria chave (com padding)\n",
        "    for num in range(256):\n",
        "      numeric_key = bin(num)[2:]\n",
        "      numeric_key_8bit_value = format(num, '08b')\n",
        "      dictionary.insert(numeric_key, numeric_key_8bit_value)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os número de 0 até 255, cada um representando um símbolo ASCII\n",
        "    decompression_size = 9 # Começaremos puxando 9 bits do arquivo comprimido por vez\n",
        "    next_size_limit = 2 * 256 # Os 9 bits serão suficientes até que o tamanho do dicionário atinja 512 elementos\n",
        "\n",
        "    # Abrindo o arquivo já comprimido e convertendo seus bytes em uma única string\n",
        "    compressed_data = \"\"\n",
        "    try:\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        file_data = file.read()\n",
        "        compressed_data = ''.join(format(byte, '08b') for byte in file_data)\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError:\n",
        "      print(f\"File not found: {file_path}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Error reading the file: {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "    # Retirando os bits de padding do arquivo comprimido\n",
        "    padding_size = int(compressed_data[:8], 2)\n",
        "    compressed_data = compressed_data[(8 + padding_size):]\n",
        "\n",
        "    # Inicializando as variáveis que serão empregadas posteriormente\n",
        "    string = compressed_data[:decompression_size]\n",
        "    string = string[-8:]\n",
        "\n",
        "    compressed_data = compressed_data[decompression_size:]\n",
        "    decompressed_data = [string]\n",
        "\n",
        "    # Aplicando a descompressão LZW\n",
        "    while(len(compressed_data) > 0):\n",
        "        # Caso em que o dicionário tem tamanho dinâmico\n",
        "        if(dict_size == next_size_limit - 1):\n",
        "          decompression_size += 1\n",
        "          next_size_limit *= 2\n",
        "\n",
        "        k = compressed_data[:decompression_size]\n",
        "        compressed_data = compressed_data[decompression_size:]\n",
        "\n",
        "        k = remove_leading_zeros(k)\n",
        "\n",
        "        if dictionary.search(k) != None:\n",
        "          entry = dictionary.search(k).value\n",
        "        else:\n",
        "          new_value_entry_concat = string[:8]\n",
        "          entry = string + new_value_entry_concat\n",
        "\n",
        "        decompressed_data.append(entry)\n",
        "        new_key = bin(dict_size)[2:] if dict_size != 0 else '0'\n",
        "        dictionary.insert(new_key, string + entry[:8])\n",
        "        dict_size += 1\n",
        "\n",
        "        string = entry\n",
        "\n",
        "    decompressed_concat_string = ''.join(decompressed_data)\n",
        "\n",
        "    # Checando algum possível erro que possa ter ocorrido na descompressão (o tamanho do arquivo final deve ser um múltiplo de 8)\n",
        "    if len(decompressed_concat_string) % 8 != 0:\n",
        "      raise ValueError(\"O arquivo descomprimido não tem um número inteiro de bytes!\")\n",
        "\n",
        "    # Transformando a string binárias em bytes individuais\n",
        "    byte_chunks = [decompressed_concat_string[i:i+8] for i in range(0, len(decompressed_concat_string), 8)]\n",
        "    bytes_ = [int(chunk, 2) for chunk in byte_chunks]\n",
        "\n",
        "    # Convert integers to their ASCII characters\n",
        "    ascii_characters = [chr(i) for i in bytes_]\n",
        "    # Join characters into a string (optional)\n",
        "    ascii_string = ''.join(ascii_characters)\n",
        "\n",
        "    # Gerando o arquivo inicial\n",
        "    switch = {\n",
        "        '.txt': write_txt_file,\n",
        "        '.bmp': write_image_file,\n",
        "        '.tiff': write_image_file # Não sei se está funcionando\n",
        "        }\n",
        "    handler = switch.get(file_extension)\n",
        "    if handler:\n",
        "        handler(bytes_, f\"decompressed_{original_file_name}{original_file_extension}\")\n",
        "    else:\n",
        "        print(\"Unsupported file type.\")\n",
        "'''"
      ],
      "metadata": {
        "id": "OSSNHWe9n2kA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "b4b9a633-9e4c-4fde-8ff3-4cbe44b1625a"
      },
      "execution_count": 1115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nfrom typing import Tuple\\nimport struct\\n\\n# Para debug\\ndef binary_to_chars(binary_string):\\n    # Ensure the binary string length is a multiple of 8 (since each character is 8 bits)\\n    if len(binary_string) % 8 != 0:\\n        raise ValueError(\"Binary string length must be a multiple of 8.\")\\n\\n    # Split the binary string into chunks of 8 bits\\n    chars = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\\n\\n    # Convert each 8-bit binary chunk to its corresponding character\\n    result = \\'\\'.join(chr(int(char, 2)) for char in chars)\\n\\n    return result\\n\\n# Função para converter um conjunto de bytes em um \\'.txt\\'\\ndef write_txt_file(decoded_bytes, output_file):\\n    decoded_string = \\'\\'.join([chr(byte) for byte in decoded_bytes])\\n    with open(output_file, \\'w\\', encoding=\\'utf-8\\') as file:\\n        file.write(decoded_string)\\n\\n# Função para converter um conjunto de bytes em um \\'.bmp\\' ou \\'.tiff\\'\\ndef write_image_file(decoded_bytes, output_file):\\n    with open(output_file, \\'wb\\') as file:\\n        file.write(bytes(decoded_bytes))\\n\\n# Função para remover zeros à esquerda em uma string binárias\\ndef remove_leading_zeros(binary_str):\\n  return binary_str.lstrip(\\'0\\') or \\'0\\'\\n\\nclass TrieLZW:\\n  # Realiza a compressão LZW do arquivo passado como parâmetro\\n  def compress(self, file_path: str=\"\") -> Tuple[str, str]:\\n    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\\n    dictionary = CompactTrie()\\n\\n    # Inicializando todas as chaves de 00000000 até 11111111 no dicionário, com respectivos valores sendo a própria chave\\n    for num in range(256):\\n      byte_num = format(num, \\'08b\\')\\n      dictionary.insert(byte_num, byte_num)\\n\\n    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\\n    num_bits_values = 9 # Começaremos usando 9 bits para representar códigos a partir de agora\\n    next_dict_size_limit = 2 * 256 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\\n\\n    # Inicializando variáveis utilizadas pela compressão LZW\\n    string = \"\"\\n    compressed_data = []\\n\\n    # Aplicando a compressão LZW, considerando cada byte do arquivo orignal como um símbolo de entrada\\n    try:\\n      count = 256\\n      with open(file_path, \"rb\") as file:\\n        while (byte := file.read(1)):\\n          symbol = bin(int.from_bytes(byte, \"big\"))[2:].zfill(8)\\n\\n          string_plus_symbol = string + symbol\\n\\n          if dictionary.search(string_plus_symbol) != None:\\n              string = string_plus_symbol\\n          else:\\n            # Caso em que o dicionário tem tamanho dinâmico\\n            if(dict_size == next_dict_size_limit):\\n                num_bits_values += 1\\n                next_dict_size_limit *= 2\\n\\n            current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\\n            compressed_data.append(current_string_formatted_binary_value)\\n            new_key_value = bin(dict_size)[2:].zfill(num_bits_values)\\n            dictionary.insert(string_plus_symbol, new_key_value)\\n            dict_size += 1\\n            string = symbol\\n\\n        if(dictionary.search(string) != None):\\n          current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\\n          compressed_data.append(current_string_formatted_binary_value)\\n\\n    # Tratando erros que podem ocorrer na abertura de um arquivo\\n    except FileNotFoundError as e:\\n      print(f\"Arquivo não encontrado -> {e}\")\\n    except IOError as e:\\n      print(f\"Erro de I/O -> {e}\")\\n    except Exception as e:\\n      print(f\"Um erro ocorreu: {e}\")\\n\\n    # Salvando o nome do arquivo original e sua extensão para que o arquivo de compressão possa ser salvo\\n    file_name, file_extension = os.path.splitext(file_path)\\n\\n    with open(f\"compressed_{file_name}.bin\", \"wb\") as file:\\n      # Convertendo os códigos para uma única string\\n      final_concat_string_data = \\'\\'.join(compressed_data)\\n\\n      # Verificando se algum padding deverá ser adicionado para que tenhamos um número inteiro de bytes no arquivo comprimido\\n      padding_size = (8 - len(final_concat_string_data) % 8) % 8\\n      final_concat_string_data = \\'0\\' * padding_size + final_concat_string_data\\n\\n      # Adicionando uma flag, no arquivo comprimido, para representar o tamanho do padding que foi adicionado\\n      file.write(bytes([padding_size]))\\n\\n      # Convertendo a string de dados comprimidos para bytes e escrevendo no arquivo comprimido final\\n      bits = []\\n      for char in final_concat_string_data:\\n        bits.append(1 if char == \\'1\\' else 0)\\n      byte = 0\\n      bit_count = 0\\n      for bit in bits:\\n        byte = (byte << 1) | bit\\n        bit_count += 1\\n        if bit_count == 8:\\n          file.write(bytes([byte]))\\n          byte = 0\\n          bit_count = 0\\n\\n      return [file_name, file_extension]\\n\\n  # Realiza a descompressão LZW do arquivo passado como parâmetro\\n  def decompress(self, file_path: str=\"\", original_file_name: str=\"\", original_file_extension: str=\"\") -> None:\\n    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\\n    dictionary = CompactTrie()\\n\\n    # Inicializando todas as chaves de 0, 1, 10, 11, 100, ... até 11111111 no dicionário (sem padding), com respectivos valores sendo a própria chave (com padding)\\n    for num in range(256):\\n      numeric_key = bin(num)[2:]\\n      numeric_key_8bit_value = format(num, \\'08b\\')\\n      dictionary.insert(numeric_key, numeric_key_8bit_value)\\n\\n    dict_size = 256 # O dicionário começa com todos os número de 0 até 255, cada um representando um símbolo ASCII\\n    decompression_size = 9 # Começaremos puxando 9 bits do arquivo comprimido por vez\\n    next_size_limit = 2 * 256 # Os 9 bits serão suficientes até que o tamanho do dicionário atinja 512 elementos\\n\\n    # Abrindo o arquivo já comprimido e convertendo seus bytes em uma única string\\n    compressed_data = \"\"\\n    try:\\n      with open(file_path, \"rb\") as file:\\n        file_data = file.read()\\n        compressed_data = \\'\\'.join(format(byte, \\'08b\\') for byte in file_data)\\n    # Tratando erros que podem ocorrer na abertura de um arquivo\\n    except FileNotFoundError:\\n      print(f\"File not found: {file_path}\")\\n    except IOError as e:\\n      print(f\"Error reading the file: {e}\")\\n    except Exception as e:\\n      print(f\"An unexpected error occurred: {e}\")\\n\\n    # Retirando os bits de padding do arquivo comprimido\\n    padding_size = int(compressed_data[:8], 2)\\n    compressed_data = compressed_data[(8 + padding_size):]\\n\\n    # Inicializando as variáveis que serão empregadas posteriormente\\n    string = compressed_data[:decompression_size]\\n    string = string[-8:]\\n\\n    compressed_data = compressed_data[decompression_size:]\\n    decompressed_data = [string]\\n\\n    # Aplicando a descompressão LZW\\n    while(len(compressed_data) > 0):\\n        # Caso em que o dicionário tem tamanho dinâmico\\n        if(dict_size == next_size_limit - 1):\\n          decompression_size += 1\\n          next_size_limit *= 2\\n\\n        k = compressed_data[:decompression_size]\\n        compressed_data = compressed_data[decompression_size:]\\n\\n        k = remove_leading_zeros(k)\\n\\n        if dictionary.search(k) != None:\\n          entry = dictionary.search(k).value\\n        else:\\n          new_value_entry_concat = string[:8]\\n          entry = string + new_value_entry_concat\\n\\n        decompressed_data.append(entry)\\n        new_key = bin(dict_size)[2:] if dict_size != 0 else \\'0\\'\\n        dictionary.insert(new_key, string + entry[:8])\\n        dict_size += 1\\n\\n        string = entry\\n\\n    decompressed_concat_string = \\'\\'.join(decompressed_data)\\n\\n    # Checando algum possível erro que possa ter ocorrido na descompressão (o tamanho do arquivo final deve ser um múltiplo de 8)\\n    if len(decompressed_concat_string) % 8 != 0:\\n      raise ValueError(\"O arquivo descomprimido não tem um número inteiro de bytes!\")\\n\\n    # Transformando a string binárias em bytes individuais\\n    byte_chunks = [decompressed_concat_string[i:i+8] for i in range(0, len(decompressed_concat_string), 8)]\\n    bytes_ = [int(chunk, 2) for chunk in byte_chunks]\\n\\n    # Convert integers to their ASCII characters\\n    ascii_characters = [chr(i) for i in bytes_]\\n    # Join characters into a string (optional)\\n    ascii_string = \\'\\'.join(ascii_characters)\\n\\n    # Gerando o arquivo inicial\\n    switch = {\\n        \\'.txt\\': write_txt_file,\\n        \\'.bmp\\': write_image_file,\\n        \\'.tiff\\': write_image_file # Não sei se está funcionando\\n        }\\n    handler = switch.get(file_extension)\\n    if handler:\\n        handler(bytes_, f\"decompressed_{original_file_name}{original_file_extension}\")\\n    else:\\n        print(\"Unsupported file type.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementação das duas versões:"
      ],
      "metadata": {
        "id": "ebVCdM99zGKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "from typing import Tuple\n",
        "import struct\n",
        "\n",
        "# Para debug\n",
        "def binary_to_chars(binary_string):\n",
        "    # Ensure the binary string length is a multiple of 8 (since each character is 8 bits)\n",
        "    if len(binary_string) % 8 != 0:\n",
        "        raise ValueError(\"Binary string length must be a multiple of 8.\")\n",
        "\n",
        "    # Split the binary string into chunks of 8 bits\n",
        "    chars = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\n",
        "\n",
        "    # Convert each 8-bit binary chunk to its corresponding character\n",
        "    result = ''.join(chr(int(char, 2)) for char in chars)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Função para converter um conjunto de bytes em um '.txt'\n",
        "def write_txt_file(decoded_bytes, output_file):\n",
        "    decoded_string = ''.join([chr(byte) for byte in decoded_bytes])\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(decoded_string)\n",
        "\n",
        "# Função para converter um conjunto de bytes em um '.bmp' ou '.tiff'\n",
        "def write_image_file(decoded_bytes, output_file):\n",
        "    with open(output_file, 'wb') as file:\n",
        "        file.write(bytes(decoded_bytes))\n",
        "\n",
        "# Função para remover zeros à esquerda em uma string binárias\n",
        "def remove_leading_zeros(binary_str):\n",
        "  return binary_str.lstrip('0') or '0'\n",
        "\n",
        "class TrieLZW:\n",
        "  # Realiza a compressão LZW do arquivo passado como parâmetro\n",
        "  def compress(self, file_path: str=\"\", compression_type: str=\"s\") -> Tuple[str, str]:\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 00000000 até 11111111 no dicionário, com respectivos valores sendo a própria chave\n",
        "    for num in range(256):\n",
        "      byte_num = format(num, '08b')\n",
        "      dictionary.insert(byte_num, byte_num)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\n",
        "    reset = False\n",
        "    if(compression_type == \"s\"):\n",
        "      num_bits_values = 12 # No caso estático, os códigos terão tamanho 12 bits\n",
        "      dict_size_limit = 2 ** num_bits_values # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095)\n",
        "    else:\n",
        "      num_bits_values = 9 # No caso estático dinâmico, os códigos terão tamanho 9 bits inicialmente\n",
        "      next_dict_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\n",
        "\n",
        "    # Inicializando variáveis utilizadas pela compressão LZW\n",
        "    string = \"\"\n",
        "    compressed_data = []\n",
        "\n",
        "    # Aplicando a compressão LZW, considerando cada byte do arquivo original como um símbolo de entrada\n",
        "    try:\n",
        "      count = 256\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        while (byte := file.read(1)):\n",
        "          symbol = bin(int.from_bytes(byte, \"big\"))[2:].zfill(8)\n",
        "\n",
        "          string_plus_symbol = string + symbol\n",
        "\n",
        "          #print(f\"Buscando {string_plus_symbol}\")\n",
        "          if dictionary.search(string_plus_symbol) != None:\n",
        "              string = string_plus_symbol\n",
        "          else:\n",
        "            # Reiniciando o dicionário no algoritmo estático\n",
        "            if(compression_type == \"s\"):\n",
        "              if(dict_size == dict_size_limit - 1):\n",
        "                reset = True\n",
        "            # Expandindo os códigos no algoritmo dinâmico\n",
        "            else:\n",
        "              if(dict_size == next_dict_size_limit):\n",
        "                  num_bits_values += 1\n",
        "                  next_dict_size_limit *= 2\n",
        "\n",
        "            current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "            compressed_data.append(current_string_formatted_binary_value)\n",
        "            new_key_value = bin(dict_size)[2:].zfill(num_bits_values)\n",
        "            dictionary.insert(string_plus_symbol, new_key_value)\n",
        "            dict_size += 1\n",
        "            string = symbol\n",
        "\n",
        "          if(reset):\n",
        "            if(dictionary.search(string) != None):\n",
        "              current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "              compressed_data.append(current_string_formatted_binary_value)\n",
        "            #print(\"RESET!\")\n",
        "            string = \"\"\n",
        "            reset = False\n",
        "            dict_size = 256\n",
        "            dictionary = CompactTrie()\n",
        "            for num in range(256):\n",
        "              byte_num = format(num, '08b')\n",
        "              dictionary.insert(byte_num, byte_num)\n",
        "\n",
        "        if(dictionary.search(string) != None):\n",
        "          current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "          compressed_data.append(current_string_formatted_binary_value)\n",
        "\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError as e:\n",
        "      print(f\"Arquivo não encontrado -> {e}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Erro de I/O -> {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Um erro ocorreu: {e}\")\n",
        "\n",
        "    # Salvando o nome do arquivo original e sua extensão para que o arquivo de compressão possa ser salvo\n",
        "    file_name, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "    with open(f\"compressed_{file_name}.bin\", \"wb\") as file:\n",
        "      # Convertendo os códigos para uma única string\n",
        "      final_concat_string_data = ''.join(compressed_data)\n",
        "\n",
        "      # Verificando se algum padding deverá ser adicionado para que tenhamos um número inteiro de bytes no arquivo comprimido\n",
        "      padding_size = (8 - len(final_concat_string_data) % 8) % 8\n",
        "      final_concat_string_data = '0' * padding_size + final_concat_string_data\n",
        "\n",
        "      # Adicionando uma flag, no arquivo comprimido, para representar o tamanho do padding que foi adicionado\n",
        "      file.write(bytes([padding_size]))\n",
        "\n",
        "      # Convertendo a string de dados comprimidos para bytes e escrevendo no arquivo comprimido final\n",
        "      bits = []\n",
        "      for char in final_concat_string_data:\n",
        "        bits.append(1 if char == '1' else 0)\n",
        "      byte = 0\n",
        "      bit_count = 0\n",
        "      for bit in bits:\n",
        "        byte = (byte << 1) | bit\n",
        "        bit_count += 1\n",
        "        if bit_count == 8:\n",
        "          file.write(bytes([byte]))\n",
        "          byte = 0\n",
        "          bit_count = 0\n",
        "\n",
        "      return [file_name, file_extension]\n",
        "\n",
        "  # Realiza a descompressão LZW do arquivo passado como parâmetro\n",
        "  def decompress(self, file_path: str=\"\", compression_type: str=\"s\", original_file_name: str=\"\", original_file_extension: str=\"\") -> None:\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 0, 1, 10, 11, 100, ... até 11111111 no dicionário (sem padding), com respectivos valores sendo a própria chave (com padding)\n",
        "    for num in range(256):\n",
        "      numeric_key = bin(num)[2:]\n",
        "      numeric_key_8bit_value = format(num, '08b')\n",
        "      dictionary.insert(numeric_key, numeric_key_8bit_value)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\n",
        "    reset = False\n",
        "    if(compression_type == \"s\"):\n",
        "      decompression_size = 12 # Sempre puxaremos 12 bits do arquivo comprimido por vez\n",
        "      dict_size_limit = 2 ** decompression_size # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095)\n",
        "    else:\n",
        "      decompression_size = 9 # Começaremos puxando 9 bits do arquivo comprimido por vez\n",
        "      next_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\n",
        "\n",
        "    # Abrindo o arquivo já comprimido e convertendo seus bytes em uma única string\n",
        "    compressed_data = \"\"\n",
        "    try:\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        file_data = file.read()\n",
        "        compressed_data = ''.join(format(byte, '08b') for byte in file_data)\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError:\n",
        "      print(f\"File not found: {file_path}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Error reading the file: {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "    # Retirando os bits de padding do arquivo comprimido\n",
        "    padding_size = int(compressed_data[:8], 2)\n",
        "    compressed_data = compressed_data[(8 + padding_size):]\n",
        "\n",
        "    # Inicializando as variáveis que serão empregadas posteriormente\n",
        "    string = compressed_data[:decompression_size]\n",
        "    string = string[-8:]\n",
        "    compressed_data = compressed_data[decompression_size:]\n",
        "    decompressed_data = [string]\n",
        "\n",
        "    # Aplicando a descompressão LZW\n",
        "    while(len(compressed_data) > 0):\n",
        "        if(compression_type == \"s\"):\n",
        "          # Caso em que os códigos têm tamanho estático\n",
        "          if(dict_size == dict_size_limit - 1):\n",
        "            reset = True\n",
        "        else:\n",
        "          # Caso em que os códigos têm tamanho dinâmico\n",
        "          if(dict_size == next_size_limit - 1):\n",
        "            decompression_size += 1\n",
        "            next_size_limit *= 2\n",
        "\n",
        "        k = compressed_data[:decompression_size]\n",
        "        compressed_data = compressed_data[decompression_size:]\n",
        "\n",
        "        k = remove_leading_zeros(k)\n",
        "\n",
        "        if dictionary.search(k) != None:\n",
        "          entry = dictionary.search(k).value\n",
        "        else:\n",
        "          new_value_entry_concat = string[:8]\n",
        "          entry = string + new_value_entry_concat\n",
        "\n",
        "        decompressed_data.append(entry)\n",
        "        print(entry)\n",
        "        new_key = bin(dict_size)[2:] if dict_size != 0 else '0'\n",
        "        dictionary.insert(new_key, string + entry[:8])\n",
        "        dict_size += 1\n",
        "        string = entry\n",
        "\n",
        "        if(reset):\n",
        "          #print(\"RESET!\")\n",
        "          #decompressed_data.append('01111010')\n",
        "          reset = False\n",
        "          dict_size = 256\n",
        "          dictionary = CompactTrie()\n",
        "          string = compressed_data[:decompression_size]\n",
        "          string = string[-8:]\n",
        "          compressed_data = compressed_data[decompression_size:]\n",
        "\n",
        "    decompressed_concat_string = ''.join(decompressed_data)\n",
        "\n",
        "    # Checando algum possível erro que possa ter ocorrido na descompressão (o tamanho do arquivo final deve ser um múltiplo de 8)\n",
        "    if len(decompressed_concat_string) % 8 != 0:\n",
        "      raise ValueError(\"O arquivo descomprimido não tem um número inteiro de bytes!\")\n",
        "\n",
        "    # Transformando a string binárias em bytes individuais\n",
        "    byte_chunks = [decompressed_concat_string[i:i+8] for i in range(0, len(decompressed_concat_string), 8)]\n",
        "    bytes_ = [int(chunk, 2) for chunk in byte_chunks]\n",
        "\n",
        "    # Convert integers to their ASCII characters\n",
        "    ascii_characters = [chr(i) for i in bytes_]\n",
        "    # Join characters into a string (optional)\n",
        "    ascii_string = ''.join(ascii_characters)\n",
        "\n",
        "    # Gerando o arquivo inicial\n",
        "    switch = {\n",
        "        '.txt': write_txt_file,\n",
        "        '.bmp': write_image_file,\n",
        "        '.tiff': write_image_file # Não sei se está funcionando\n",
        "        }\n",
        "    handler = switch.get(file_extension)\n",
        "    if handler:\n",
        "        handler(bytes_, f\"decompressed_{original_file_name}{original_file_extension}\")\n",
        "    else:\n",
        "        print(\"Unsupported file type.\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "xpEljvTjzDjo",
        "outputId": "2fcc9a90-7ee8-401f-b48a-e48eb9afe6c3"
      },
      "execution_count": 1116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nfrom typing import Tuple\\nimport struct\\n\\n# Para debug\\ndef binary_to_chars(binary_string):\\n    # Ensure the binary string length is a multiple of 8 (since each character is 8 bits)\\n    if len(binary_string) % 8 != 0:\\n        raise ValueError(\"Binary string length must be a multiple of 8.\")\\n\\n    # Split the binary string into chunks of 8 bits\\n    chars = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\\n\\n    # Convert each 8-bit binary chunk to its corresponding character\\n    result = \\'\\'.join(chr(int(char, 2)) for char in chars)\\n\\n    return result\\n\\n# Função para converter um conjunto de bytes em um \\'.txt\\'\\ndef write_txt_file(decoded_bytes, output_file):\\n    decoded_string = \\'\\'.join([chr(byte) for byte in decoded_bytes])\\n    with open(output_file, \\'w\\', encoding=\\'utf-8\\') as file:\\n        file.write(decoded_string)\\n\\n# Função para converter um conjunto de bytes em um \\'.bmp\\' ou \\'.tiff\\'\\ndef write_image_file(decoded_bytes, output_file):\\n    with open(output_file, \\'wb\\') as file:\\n        file.write(bytes(decoded_bytes))\\n\\n# Função para remover zeros à esquerda em uma string binárias\\ndef remove_leading_zeros(binary_str):\\n  return binary_str.lstrip(\\'0\\') or \\'0\\'\\n\\nclass TrieLZW:\\n  # Realiza a compressão LZW do arquivo passado como parâmetro\\n  def compress(self, file_path: str=\"\", compression_type: str=\"s\") -> Tuple[str, str]:\\n    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\\n    dictionary = CompactTrie()\\n\\n    # Inicializando todas as chaves de 00000000 até 11111111 no dicionário, com respectivos valores sendo a própria chave\\n    for num in range(256):\\n      byte_num = format(num, \\'08b\\')\\n      dictionary.insert(byte_num, byte_num)\\n\\n    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\\n    reset = False\\n    if(compression_type == \"s\"):\\n      num_bits_values = 12 # No caso estático, os códigos terão tamanho 12 bits\\n      dict_size_limit = 2 ** num_bits_values # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095) \\n    else:\\n      num_bits_values = 9 # No caso estático dinâmico, os códigos terão tamanho 9 bits inicialmente\\n      next_dict_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\\n\\n    # Inicializando variáveis utilizadas pela compressão LZW\\n    string = \"\"\\n    compressed_data = []\\n\\n    # Aplicando a compressão LZW, considerando cada byte do arquivo original como um símbolo de entrada\\n    try:\\n      count = 256\\n      with open(file_path, \"rb\") as file:\\n        while (byte := file.read(1)):\\n          symbol = bin(int.from_bytes(byte, \"big\"))[2:].zfill(8)\\n\\n          string_plus_symbol = string + symbol\\n\\n          #print(f\"Buscando {string_plus_symbol}\")\\n          if dictionary.search(string_plus_symbol) != None:\\n              string = string_plus_symbol\\n          else:\\n            # Reiniciando o dicionário no algoritmo estático\\n            if(compression_type == \"s\"):\\n              if(dict_size == dict_size_limit - 1):\\n                reset = True\\n            # Expandindo os códigos no algoritmo dinâmico\\n            else:\\n              if(dict_size == next_dict_size_limit):\\n                  num_bits_values += 1\\n                  next_dict_size_limit *= 2\\n\\n            current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\\n            compressed_data.append(current_string_formatted_binary_value)\\n            new_key_value = bin(dict_size)[2:].zfill(num_bits_values)\\n            dictionary.insert(string_plus_symbol, new_key_value)\\n            dict_size += 1\\n            string = symbol\\n\\n          if(reset):\\n            if(dictionary.search(string) != None):\\n              current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\\n              compressed_data.append(current_string_formatted_binary_value)\\n            #print(\"RESET!\")\\n            string = \"\"\\n            reset = False\\n            dict_size = 256\\n            dictionary = CompactTrie()\\n            for num in range(256):\\n              byte_num = format(num, \\'08b\\')\\n              dictionary.insert(byte_num, byte_num)\\n\\n        if(dictionary.search(string) != None):\\n          current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\\n          compressed_data.append(current_string_formatted_binary_value)\\n\\n    # Tratando erros que podem ocorrer na abertura de um arquivo\\n    except FileNotFoundError as e:\\n      print(f\"Arquivo não encontrado -> {e}\")\\n    except IOError as e:\\n      print(f\"Erro de I/O -> {e}\")\\n    except Exception as e:\\n      print(f\"Um erro ocorreu: {e}\")\\n\\n    # Salvando o nome do arquivo original e sua extensão para que o arquivo de compressão possa ser salvo\\n    file_name, file_extension = os.path.splitext(file_path)\\n\\n    with open(f\"compressed_{file_name}.bin\", \"wb\") as file:\\n      # Convertendo os códigos para uma única string\\n      final_concat_string_data = \\'\\'.join(compressed_data)\\n\\n      # Verificando se algum padding deverá ser adicionado para que tenhamos um número inteiro de bytes no arquivo comprimido\\n      padding_size = (8 - len(final_concat_string_data) % 8) % 8\\n      final_concat_string_data = \\'0\\' * padding_size + final_concat_string_data\\n\\n      # Adicionando uma flag, no arquivo comprimido, para representar o tamanho do padding que foi adicionado\\n      file.write(bytes([padding_size]))\\n\\n      # Convertendo a string de dados comprimidos para bytes e escrevendo no arquivo comprimido final\\n      bits = []\\n      for char in final_concat_string_data:\\n        bits.append(1 if char == \\'1\\' else 0)\\n      byte = 0\\n      bit_count = 0\\n      for bit in bits:\\n        byte = (byte << 1) | bit\\n        bit_count += 1\\n        if bit_count == 8:\\n          file.write(bytes([byte]))\\n          byte = 0\\n          bit_count = 0\\n\\n      return [file_name, file_extension]\\n\\n  # Realiza a descompressão LZW do arquivo passado como parâmetro\\n  def decompress(self, file_path: str=\"\", compression_type: str=\"s\", original_file_name: str=\"\", original_file_extension: str=\"\") -> None:\\n    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\\n    dictionary = CompactTrie()\\n\\n    # Inicializando todas as chaves de 0, 1, 10, 11, 100, ... até 11111111 no dicionário (sem padding), com respectivos valores sendo a própria chave (com padding)\\n    for num in range(256):\\n      numeric_key = bin(num)[2:]\\n      numeric_key_8bit_value = format(num, \\'08b\\')\\n      dictionary.insert(numeric_key, numeric_key_8bit_value)\\n\\n    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\\n    reset = False\\n    if(compression_type == \"s\"):\\n      decompression_size = 12 # Sempre puxaremos 12 bits do arquivo comprimido por vez\\n      dict_size_limit = 2 ** decompression_size # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095)\\n    else:\\n      decompression_size = 9 # Começaremos puxando 9 bits do arquivo comprimido por vez\\n      next_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\\n\\n    # Abrindo o arquivo já comprimido e convertendo seus bytes em uma única string\\n    compressed_data = \"\"\\n    try:\\n      with open(file_path, \"rb\") as file:\\n        file_data = file.read()\\n        compressed_data = \\'\\'.join(format(byte, \\'08b\\') for byte in file_data)\\n    # Tratando erros que podem ocorrer na abertura de um arquivo\\n    except FileNotFoundError:\\n      print(f\"File not found: {file_path}\")\\n    except IOError as e:\\n      print(f\"Error reading the file: {e}\")\\n    except Exception as e:\\n      print(f\"An unexpected error occurred: {e}\")\\n\\n    # Retirando os bits de padding do arquivo comprimido\\n    padding_size = int(compressed_data[:8], 2)\\n    compressed_data = compressed_data[(8 + padding_size):]\\n\\n    # Inicializando as variáveis que serão empregadas posteriormente\\n    string = compressed_data[:decompression_size]\\n    string = string[-8:]\\n    compressed_data = compressed_data[decompression_size:]\\n    decompressed_data = [string]\\n\\n    # Aplicando a descompressão LZW\\n    while(len(compressed_data) > 0):\\n        if(compression_type == \"s\"):\\n          # Caso em que os códigos têm tamanho estático\\n          if(dict_size == dict_size_limit - 1):\\n            reset = True\\n        else:\\n          # Caso em que os códigos têm tamanho dinâmico\\n          if(dict_size == next_size_limit - 1):\\n            decompression_size += 1\\n            next_size_limit *= 2\\n\\n        k = compressed_data[:decompression_size]\\n        compressed_data = compressed_data[decompression_size:]\\n\\n        k = remove_leading_zeros(k)\\n\\n        if dictionary.search(k) != None:\\n          entry = dictionary.search(k).value\\n        else:\\n          new_value_entry_concat = string[:8]\\n          entry = string + new_value_entry_concat\\n\\n        decompressed_data.append(entry)\\n        print(entry)\\n        new_key = bin(dict_size)[2:] if dict_size != 0 else \\'0\\'\\n        dictionary.insert(new_key, string + entry[:8])\\n        dict_size += 1\\n        string = entry\\n\\n        if(reset):\\n          #print(\"RESET!\")\\n          #decompressed_data.append(\\'01111010\\')\\n          reset = False\\n          dict_size = 256\\n          dictionary = CompactTrie()\\n          string = compressed_data[:decompression_size]\\n          string = string[-8:]\\n          compressed_data = compressed_data[decompression_size:]\\n\\n    decompressed_concat_string = \\'\\'.join(decompressed_data)\\n\\n    # Checando algum possível erro que possa ter ocorrido na descompressão (o tamanho do arquivo final deve ser um múltiplo de 8)\\n    if len(decompressed_concat_string) % 8 != 0:\\n      raise ValueError(\"O arquivo descomprimido não tem um número inteiro de bytes!\")\\n\\n    # Transformando a string binárias em bytes individuais\\n    byte_chunks = [decompressed_concat_string[i:i+8] for i in range(0, len(decompressed_concat_string), 8)]\\n    bytes_ = [int(chunk, 2) for chunk in byte_chunks]\\n\\n    # Convert integers to their ASCII characters\\n    ascii_characters = [chr(i) for i in bytes_]\\n    # Join characters into a string (optional)\\n    ascii_string = \\'\\'.join(ascii_characters)\\n\\n    # Gerando o arquivo inicial\\n    switch = {\\n        \\'.txt\\': write_txt_file,\\n        \\'.bmp\\': write_image_file,\\n        \\'.tiff\\': write_image_file # Não sei se está funcionando\\n        }\\n    handler = switch.get(file_extension)\\n    if handler:\\n        handler(bytes_, f\"decompressed_{original_file_name}{original_file_extension}\")\\n    else:\\n        print(\"Unsupported file type.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCIONANDO:"
      ],
      "metadata": {
        "id": "CmrWjGN88y6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "from typing import Tuple, List\n",
        "import struct\n",
        "\n",
        "# Para debug\n",
        "def binary_to_chars(binary_string):\n",
        "    # Ensure the binary string length is a multiple of 8 (since each character is 8 bits)\n",
        "    if len(binary_string) % 8 != 0:\n",
        "        raise ValueError(\"Binary string length must be a multiple of 8.\")\n",
        "\n",
        "    # Split the binary string into chunks of 8 bits\n",
        "    chars = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\n",
        "\n",
        "    # Convert each 8-bit binary chunk to its corresponding character\n",
        "    result = ''.join(chr(int(char, 2)) for char in chars)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Função para converter um conjunto de bytes em um '.txt'\n",
        "def write_txt_file(decoded_bytes, output_file):\n",
        "    decoded_string = ''.join([chr(byte) for byte in decoded_bytes])\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(decoded_string)\n",
        "\n",
        "# Função para converter um conjunto de bytes em um '.bmp' ou '.tiff'\n",
        "def write_image_file(decoded_bytes, output_file):\n",
        "    with open(output_file, 'wb') as file:\n",
        "        file.write(bytes(decoded_bytes))\n",
        "\n",
        "# Função para remover zeros à esquerda em uma string binárias\n",
        "def remove_leading_zeros(binary_str):\n",
        "  return binary_str.lstrip('0') or '0'\n",
        "\n",
        "class TrieLZW:\n",
        "  # Realiza a compressão LZW do arquivo passado como parâmetro\n",
        "  def compress(self, file_path: str=\"\", compression_type: str=\"s\") -> Tuple[str, str, List]:\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 00000000 até 11111111 no dicionário, com respectivos valores sendo a própria chave\n",
        "    for num in range(256):\n",
        "      byte_num = format(num, '08b')\n",
        "      dictionary.insert(byte_num, byte_num)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\n",
        "    reset = False\n",
        "\n",
        "    if(compression_type == \"s\"):\n",
        "      num_bits_values = 12 # No caso estático, os códigos terão tamanho 12 bits\n",
        "      dict_size_limit = 2 ** num_bits_values # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095)\n",
        "    else:\n",
        "      num_bits_values = 9 # No caso estático dinâmico, os códigos terão tamanho 9 bits inicialmente\n",
        "      next_dict_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\n",
        "\n",
        "    # Inicializando variáveis utilizadas pela compressão LZW\n",
        "    string = \"\"\n",
        "    compressed_data = []\n",
        "    resets = []\n",
        "\n",
        "    # Aplicando a compressão LZW, considerando cada byte do arquivo original como um símbolo de entrada\n",
        "    try:\n",
        "      count=0\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        while (byte := file.read(1)):\n",
        "          symbol = bin(int.from_bytes(byte, \"big\"))[2:].zfill(8)\n",
        "\n",
        "          string_plus_symbol = string + symbol\n",
        "\n",
        "          if dictionary.search(string_plus_symbol) != None:\n",
        "              string = string_plus_symbol\n",
        "          else:\n",
        "            # Reiniciando o dicionário no algoritmo estático\n",
        "            if(compression_type == \"s\"):\n",
        "              if(dict_size == dict_size_limit - 1):\n",
        "                reset = True\n",
        "            # Expandindo os códigos no algoritmo dinâmico\n",
        "            else:\n",
        "              if(dict_size == next_dict_size_limit):\n",
        "                  num_bits_values += 1\n",
        "                  next_dict_size_limit *= 2\n",
        "\n",
        "            #print(f\"{count} DICT SIZE: {dict_size}\")\n",
        "            count += 1\n",
        "            current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "            compressed_data.append(current_string_formatted_binary_value)\n",
        "            new_key_value = bin(dict_size)[2:].zfill(num_bits_values)\n",
        "            dictionary.insert(string_plus_symbol, new_key_value)\n",
        "            dict_size += 1\n",
        "            string = symbol\n",
        "\n",
        "            if(reset):\n",
        "              #print(f\"RESET\")\n",
        "              #print(f\"Último que adicionei na saída foi: {current_string_formatted_binary_value}\")\n",
        "              #print(f\"Perdendo -> {string}\")\n",
        "              #print(f\"Tamanho do dicionário atingiu {dict_size}\")\n",
        "              #print()\n",
        "\n",
        "              #if(dictionary.search(string) != None):\n",
        "                #current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "                #compressed_data.append(current_string_formatted_binary_value)\n",
        "                #resets.append(len(current_string_formatted_binary_value))\n",
        "              #else:\n",
        "                #resets.append(0)\n",
        "\n",
        "              #string = \"\"\n",
        "\n",
        "              reset = False\n",
        "              dict_size = 256\n",
        "              dictionary = CompactTrie()\n",
        "              for num in range(256):\n",
        "                byte_num = format(num, '08b')\n",
        "                dictionary.insert(byte_num, byte_num)\n",
        "\n",
        "        if(dictionary.search(string) != None):\n",
        "          current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "          compressed_data.append(current_string_formatted_binary_value)\n",
        "\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError as e:\n",
        "      print(f\"Arquivo não encontrado -> {e}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Erro de I/O -> {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Um erro ocorreu: {e}\")\n",
        "\n",
        "    # Salvando o nome do arquivo original e sua extensão para que o arquivo de compressão possa ser salvo\n",
        "    file_name, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "    with open(f\"compressed_{file_name}.bin\", \"wb\") as file:\n",
        "      # Convertendo os códigos para uma única string\n",
        "      final_concat_string_data = ''.join(compressed_data)\n",
        "\n",
        "      # Verificando se algum padding deverá ser adicionado para que tenhamos um número inteiro de bytes no arquivo comprimido\n",
        "      padding_size = (8 - len(final_concat_string_data) % 8) % 8\n",
        "      final_concat_string_data = '0' * padding_size + final_concat_string_data\n",
        "\n",
        "      # Adicionando uma flag, no arquivo comprimido, para representar o tamanho do padding que foi adicionado\n",
        "      file.write(bytes([padding_size]))\n",
        "\n",
        "      # Convertendo a string de dados comprimidos para bytes e escrevendo no arquivo comprimido final\n",
        "      bits = []\n",
        "      for char in final_concat_string_data:\n",
        "        bits.append(1 if char == '1' else 0)\n",
        "      byte = 0\n",
        "      bit_count = 0\n",
        "      for bit in bits:\n",
        "        byte = (byte << 1) | bit\n",
        "        bit_count += 1\n",
        "        if bit_count == 8:\n",
        "          file.write(bytes([byte]))\n",
        "          byte = 0\n",
        "          bit_count = 0\n",
        "\n",
        "      return file_name, file_extension\n",
        "\n",
        "  # Realiza a descompressão LZW do arquivo passado como parâmetro\n",
        "  def decompress(self, file_path: str=\"\", compression_type: str=\"s\", original_file_name: str=\"\", original_file_extension: str=\"\", resets: List[int]=[]) -> None:\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 0, 1, 10, 11, 100, ... até 11111111 no dicionário (sem padding), com respectivos valores sendo a própria chave (com padding)\n",
        "    for num in range(256):\n",
        "      numeric_key = bin(num)[2:]\n",
        "      numeric_key_8bit_value = format(num, '08b')\n",
        "      dictionary.insert(numeric_key, numeric_key_8bit_value)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\n",
        "    reset = False\n",
        "    if(compression_type == \"s\"):\n",
        "      decompression_size = 12 # Sempre puxaremos 12 bits do arquivo comprimido por vez\n",
        "      dict_size_limit = 2 ** decompression_size # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095)\n",
        "    else:\n",
        "      decompression_size = 9 # Começaremos puxando 9 bits do arquivo comprimido por vez\n",
        "      next_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\n",
        "\n",
        "    # Abrindo o arquivo já comprimido e convertendo seus bytes em uma única string\n",
        "    compressed_data = \"\"\n",
        "    try:\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        file_data = file.read()\n",
        "        compressed_data = ''.join(format(byte, '08b') for byte in file_data)\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError:\n",
        "      print(f\"File not found: {file_path}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Error reading the file: {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "    # Retirando os bits de padding do arquivo comprimido\n",
        "    padding_size = int(compressed_data[:8], 2)\n",
        "    compressed_data = compressed_data[(8 + padding_size):]\n",
        "\n",
        "    # Inicializando as variáveis que serão empregadas posteriormente\n",
        "    string = compressed_data[:decompression_size]\n",
        "    string = string[-8:]\n",
        "    compressed_data = compressed_data[decompression_size:]\n",
        "    decompressed_data = [string]\n",
        "\n",
        "    num_resets = 0\n",
        "\n",
        "    # Aplicando a descompressão LZW\n",
        "    while(len(compressed_data) > 0):\n",
        "        if(compression_type == \"s\"):\n",
        "          # Caso em que os códigos têm tamanho estático\n",
        "          if(dict_size == dict_size_limit - 1):\n",
        "            reset = True\n",
        "        else:\n",
        "          # Caso em que os códigos têm tamanho dinâmico\n",
        "          if(dict_size == next_size_limit - 1):\n",
        "            decompression_size += 1\n",
        "            next_size_limit *= 2\n",
        "\n",
        "        k = compressed_data[:decompression_size]\n",
        "        compressed_data = compressed_data[decompression_size:]\n",
        "        k = remove_leading_zeros(k)\n",
        "\n",
        "        if dictionary.search(k) != None:\n",
        "          entry = dictionary.search(k).value\n",
        "        else:\n",
        "          new_value_entry_concat = string[:8]\n",
        "          entry = string + new_value_entry_concat\n",
        "\n",
        "        decompressed_data.append(entry)\n",
        "        new_key = bin(dict_size)[2:] if dict_size != 0 else '0'\n",
        "        dictionary.insert(new_key, string + entry[:8])\n",
        "        dict_size += 1\n",
        "        string = entry\n",
        "\n",
        "        if(reset):\n",
        "          reset = False\n",
        "          dict_size = 256\n",
        "          dictionary = CompactTrie()\n",
        "          for num in range(256):\n",
        "            numeric_key = bin(num)[2:]\n",
        "            numeric_key_8bit_value = format(num, '08b')\n",
        "            dictionary.insert(numeric_key, numeric_key_8bit_value)\n",
        "\n",
        "          #string = compressed_data[:decompression_size]\n",
        "          #string = string[-8:]\n",
        "          #compressed_data = compressed_data[decompression_size:]\n",
        "\n",
        "    decompressed_concat_string = ''.join(decompressed_data)\n",
        "\n",
        "    # Checando algum possível erro que possa ter ocorrido na descompressão (o tamanho do arquivo final deve ser um múltiplo de 8)\n",
        "    if len(decompressed_concat_string) % 8 != 0:\n",
        "      raise ValueError(\"O arquivo descomprimido não tem um número inteiro de bytes!\")\n",
        "\n",
        "    # Transformando a string binárias em bytes individuais\n",
        "    byte_chunks = [decompressed_concat_string[i:i+8] for i in range(0, len(decompressed_concat_string), 8)]\n",
        "    bytes_ = [int(chunk, 2) for chunk in byte_chunks]\n",
        "\n",
        "    # Convert integers to their ASCII characters\n",
        "    ascii_characters = [chr(i) for i in bytes_]\n",
        "    # Join characters into a string (optional)\n",
        "    ascii_string = ''.join(ascii_characters)\n",
        "\n",
        "    # Gerando o arquivo inicial\n",
        "    switch = {\n",
        "        '.txt': write_txt_file,\n",
        "        '.bmp': write_image_file,\n",
        "        '.tiff': write_image_file # Não sei se está funcionando\n",
        "        }\n",
        "    handler = switch.get(file_extension)\n",
        "    if handler:\n",
        "        handler(bytes_, f\"decompressed_{original_file_name}{original_file_extension}\")\n",
        "    else:\n",
        "        print(\"Unsupported file type.\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "UBbvJpchbiSz",
        "outputId": "21120fe6-769d-4f0d-b793-73ebe0a0967f"
      },
      "execution_count": 1117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nfrom typing import Tuple, List\\nimport struct\\n\\n# Para debug\\ndef binary_to_chars(binary_string):\\n    # Ensure the binary string length is a multiple of 8 (since each character is 8 bits)\\n    if len(binary_string) % 8 != 0:\\n        raise ValueError(\"Binary string length must be a multiple of 8.\")\\n\\n    # Split the binary string into chunks of 8 bits\\n    chars = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\\n\\n    # Convert each 8-bit binary chunk to its corresponding character\\n    result = \\'\\'.join(chr(int(char, 2)) for char in chars)\\n\\n    return result\\n\\n# Função para converter um conjunto de bytes em um \\'.txt\\'\\ndef write_txt_file(decoded_bytes, output_file):\\n    decoded_string = \\'\\'.join([chr(byte) for byte in decoded_bytes])\\n    with open(output_file, \\'w\\', encoding=\\'utf-8\\') as file:\\n        file.write(decoded_string)\\n\\n# Função para converter um conjunto de bytes em um \\'.bmp\\' ou \\'.tiff\\'\\ndef write_image_file(decoded_bytes, output_file):\\n    with open(output_file, \\'wb\\') as file:\\n        file.write(bytes(decoded_bytes))\\n\\n# Função para remover zeros à esquerda em uma string binárias\\ndef remove_leading_zeros(binary_str):\\n  return binary_str.lstrip(\\'0\\') or \\'0\\'\\n\\nclass TrieLZW:\\n  # Realiza a compressão LZW do arquivo passado como parâmetro\\n  def compress(self, file_path: str=\"\", compression_type: str=\"s\") -> Tuple[str, str, List]:\\n    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\\n    dictionary = CompactTrie()\\n\\n    # Inicializando todas as chaves de 00000000 até 11111111 no dicionário, com respectivos valores sendo a própria chave\\n    for num in range(256):\\n      byte_num = format(num, \\'08b\\')\\n      dictionary.insert(byte_num, byte_num)\\n\\n    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\\n    reset = False\\n\\n    if(compression_type == \"s\"):\\n      num_bits_values = 12 # No caso estático, os códigos terão tamanho 12 bits\\n      dict_size_limit = 2 ** num_bits_values # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095) \\n    else:\\n      num_bits_values = 9 # No caso estático dinâmico, os códigos terão tamanho 9 bits inicialmente\\n      next_dict_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\\n\\n    # Inicializando variáveis utilizadas pela compressão LZW\\n    string = \"\"\\n    compressed_data = []\\n    resets = []\\n\\n    # Aplicando a compressão LZW, considerando cada byte do arquivo original como um símbolo de entrada\\n    try:\\n      count=0\\n      with open(file_path, \"rb\") as file:\\n        while (byte := file.read(1)):\\n          symbol = bin(int.from_bytes(byte, \"big\"))[2:].zfill(8)\\n\\n          string_plus_symbol = string + symbol\\n\\n          if dictionary.search(string_plus_symbol) != None:\\n              string = string_plus_symbol\\n          else:\\n            # Reiniciando o dicionário no algoritmo estático\\n            if(compression_type == \"s\"):\\n              if(dict_size == dict_size_limit - 1):\\n                reset = True\\n            # Expandindo os códigos no algoritmo dinâmico\\n            else:\\n              if(dict_size == next_dict_size_limit):\\n                  num_bits_values += 1\\n                  next_dict_size_limit *= 2\\n\\n            #print(f\"{count} DICT SIZE: {dict_size}\")\\n            count += 1\\n            current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\\n            compressed_data.append(current_string_formatted_binary_value)\\n            new_key_value = bin(dict_size)[2:].zfill(num_bits_values)\\n            dictionary.insert(string_plus_symbol, new_key_value)\\n            dict_size += 1\\n            string = symbol\\n\\n            if(reset):\\n              #print(f\"RESET\")\\n              #print(f\"Último que adicionei na saída foi: {current_string_formatted_binary_value}\")\\n              #print(f\"Perdendo -> {string}\")\\n              #print(f\"Tamanho do dicionário atingiu {dict_size}\")\\n              #print()\\n\\n              #if(dictionary.search(string) != None):\\n                #current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\\n                #compressed_data.append(current_string_formatted_binary_value)\\n                #resets.append(len(current_string_formatted_binary_value))\\n              #else:\\n                #resets.append(0)\\n\\n              #string = \"\"\\n\\n              reset = False\\n              dict_size = 256\\n              dictionary = CompactTrie()\\n              for num in range(256):\\n                byte_num = format(num, \\'08b\\')\\n                dictionary.insert(byte_num, byte_num)\\n\\n        if(dictionary.search(string) != None):\\n          current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\\n          compressed_data.append(current_string_formatted_binary_value)\\n\\n    # Tratando erros que podem ocorrer na abertura de um arquivo\\n    except FileNotFoundError as e:\\n      print(f\"Arquivo não encontrado -> {e}\")\\n    except IOError as e:\\n      print(f\"Erro de I/O -> {e}\")\\n    except Exception as e:\\n      print(f\"Um erro ocorreu: {e}\")\\n\\n    # Salvando o nome do arquivo original e sua extensão para que o arquivo de compressão possa ser salvo\\n    file_name, file_extension = os.path.splitext(file_path)\\n\\n    with open(f\"compressed_{file_name}.bin\", \"wb\") as file:\\n      # Convertendo os códigos para uma única string\\n      final_concat_string_data = \\'\\'.join(compressed_data)\\n\\n      # Verificando se algum padding deverá ser adicionado para que tenhamos um número inteiro de bytes no arquivo comprimido\\n      padding_size = (8 - len(final_concat_string_data) % 8) % 8\\n      final_concat_string_data = \\'0\\' * padding_size + final_concat_string_data\\n\\n      # Adicionando uma flag, no arquivo comprimido, para representar o tamanho do padding que foi adicionado\\n      file.write(bytes([padding_size]))\\n\\n      # Convertendo a string de dados comprimidos para bytes e escrevendo no arquivo comprimido final\\n      bits = []\\n      for char in final_concat_string_data:\\n        bits.append(1 if char == \\'1\\' else 0)\\n      byte = 0\\n      bit_count = 0\\n      for bit in bits:\\n        byte = (byte << 1) | bit\\n        bit_count += 1\\n        if bit_count == 8:\\n          file.write(bytes([byte]))\\n          byte = 0\\n          bit_count = 0\\n\\n      return file_name, file_extension\\n\\n  # Realiza a descompressão LZW do arquivo passado como parâmetro\\n  def decompress(self, file_path: str=\"\", compression_type: str=\"s\", original_file_name: str=\"\", original_file_extension: str=\"\", resets: List[int]=[]) -> None:\\n    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\\n    dictionary = CompactTrie()\\n\\n    # Inicializando todas as chaves de 0, 1, 10, 11, 100, ... até 11111111 no dicionário (sem padding), com respectivos valores sendo a própria chave (com padding)\\n    for num in range(256):\\n      numeric_key = bin(num)[2:]\\n      numeric_key_8bit_value = format(num, \\'08b\\')\\n      dictionary.insert(numeric_key, numeric_key_8bit_value)\\n\\n    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\\n    reset = False\\n    if(compression_type == \"s\"):\\n      decompression_size = 12 # Sempre puxaremos 12 bits do arquivo comprimido por vez\\n      dict_size_limit = 2 ** decompression_size # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095)\\n    else:\\n      decompression_size = 9 # Começaremos puxando 9 bits do arquivo comprimido por vez\\n      next_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\\n\\n    # Abrindo o arquivo já comprimido e convertendo seus bytes em uma única string\\n    compressed_data = \"\"\\n    try:\\n      with open(file_path, \"rb\") as file:\\n        file_data = file.read()\\n        compressed_data = \\'\\'.join(format(byte, \\'08b\\') for byte in file_data)\\n    # Tratando erros que podem ocorrer na abertura de um arquivo\\n    except FileNotFoundError:\\n      print(f\"File not found: {file_path}\")\\n    except IOError as e:\\n      print(f\"Error reading the file: {e}\")\\n    except Exception as e:\\n      print(f\"An unexpected error occurred: {e}\")\\n\\n    # Retirando os bits de padding do arquivo comprimido\\n    padding_size = int(compressed_data[:8], 2)\\n    compressed_data = compressed_data[(8 + padding_size):]\\n\\n    # Inicializando as variáveis que serão empregadas posteriormente\\n    string = compressed_data[:decompression_size]\\n    string = string[-8:]\\n    compressed_data = compressed_data[decompression_size:]\\n    decompressed_data = [string]\\n\\n    num_resets = 0\\n\\n    # Aplicando a descompressão LZW\\n    while(len(compressed_data) > 0):\\n        if(compression_type == \"s\"):\\n          # Caso em que os códigos têm tamanho estático\\n          if(dict_size == dict_size_limit - 1):\\n            reset = True\\n        else:\\n          # Caso em que os códigos têm tamanho dinâmico\\n          if(dict_size == next_size_limit - 1):\\n            decompression_size += 1\\n            next_size_limit *= 2\\n\\n        k = compressed_data[:decompression_size]\\n        compressed_data = compressed_data[decompression_size:]\\n        k = remove_leading_zeros(k)\\n\\n        if dictionary.search(k) != None:\\n          entry = dictionary.search(k).value\\n        else:\\n          new_value_entry_concat = string[:8]\\n          entry = string + new_value_entry_concat\\n\\n        decompressed_data.append(entry)\\n        new_key = bin(dict_size)[2:] if dict_size != 0 else \\'0\\'\\n        dictionary.insert(new_key, string + entry[:8])\\n        dict_size += 1\\n        string = entry\\n\\n        if(reset):\\n          reset = False\\n          dict_size = 256\\n          dictionary = CompactTrie()\\n          for num in range(256):\\n            numeric_key = bin(num)[2:]\\n            numeric_key_8bit_value = format(num, \\'08b\\')\\n            dictionary.insert(numeric_key, numeric_key_8bit_value)\\n\\n          #string = compressed_data[:decompression_size]\\n          #string = string[-8:]\\n          #compressed_data = compressed_data[decompression_size:]\\n\\n    decompressed_concat_string = \\'\\'.join(decompressed_data)\\n\\n    # Checando algum possível erro que possa ter ocorrido na descompressão (o tamanho do arquivo final deve ser um múltiplo de 8)\\n    if len(decompressed_concat_string) % 8 != 0:\\n      raise ValueError(\"O arquivo descomprimido não tem um número inteiro de bytes!\")\\n\\n    # Transformando a string binárias em bytes individuais\\n    byte_chunks = [decompressed_concat_string[i:i+8] for i in range(0, len(decompressed_concat_string), 8)]\\n    bytes_ = [int(chunk, 2) for chunk in byte_chunks]\\n\\n    # Convert integers to their ASCII characters\\n    ascii_characters = [chr(i) for i in bytes_]\\n    # Join characters into a string (optional)\\n    ascii_string = \\'\\'.join(ascii_characters)\\n\\n    # Gerando o arquivo inicial\\n    switch = {\\n        \\'.txt\\': write_txt_file,\\n        \\'.bmp\\': write_image_file,\\n        \\'.tiff\\': write_image_file # Não sei se está funcionando\\n        }\\n    handler = switch.get(file_extension)\\n    if handler:\\n        handler(bytes_, f\"decompressed_{original_file_name}{original_file_extension}\")\\n    else:\\n        print(\"Unsupported file type.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Tuple, List\n",
        "import struct\n",
        "\n",
        "# Para debug\n",
        "def binary_to_chars(binary_string):\n",
        "    # Ensure the binary string length is a multiple of 8 (since each character is 8 bits)\n",
        "    if len(binary_string) % 8 != 0:\n",
        "        raise ValueError(\"Binary string length must be a multiple of 8.\")\n",
        "\n",
        "    # Split the binary string into chunks of 8 bits\n",
        "    chars = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\n",
        "\n",
        "    # Convert each 8-bit binary chunk to its corresponding character\n",
        "    result = ''.join(chr(int(char, 2)) for char in chars)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Função para converter um conjunto de bytes em um '.txt'\n",
        "def write_txt_file(decoded_bytes, output_file):\n",
        "    decoded_string = ''.join([chr(byte) for byte in decoded_bytes])\n",
        "    with open(output_file, 'w', encoding='utf-8') as file:\n",
        "        file.write(decoded_string)\n",
        "\n",
        "# Função para converter um conjunto de bytes em um '.bmp' ou '.tiff'\n",
        "def write_image_file(decoded_bytes, output_file):\n",
        "    with open(output_file, 'wb') as file:\n",
        "        file.write(bytes(decoded_bytes))\n",
        "\n",
        "# Função para remover zeros à esquerda em uma string binárias\n",
        "def remove_leading_zeros(binary_str):\n",
        "  return binary_str.lstrip('0') or '0'\n",
        "\n",
        "# Classe que implementa o algoritmo LZW, empregando árvores Tries Binárias como dicionários\n",
        "class TrieLZW:\n",
        "  # Realiza a compressão LZW do arquivo passado como parâmetro\n",
        "  def compress(self, file_path, compression_type, codes_max_size) -> Tuple[str, str, List]:\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 00000000 até 11111111 no dicionário, com respectivos valores sendo a própria chave\n",
        "    for num in range(256):\n",
        "      byte_num = format(num, '08b')\n",
        "      dictionary.insert(byte_num, byte_num)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\n",
        "    reset = False\n",
        "\n",
        "    if(compression_type == \"s\"):\n",
        "      num_bits_values = 12 # No caso estático, os códigos terão tamanho 12 bits\n",
        "      dict_size_limit = 2 ** num_bits_values # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095)\n",
        "    else:\n",
        "      num_bits_values = 9 # No caso estático dinâmico, os códigos terão tamanho 9 bits inicialmente\n",
        "      next_dict_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\n",
        "\n",
        "    # Inicializando variáveis utilizadas pela compressão LZW\n",
        "    string = \"\"\n",
        "    compressed_data = []\n",
        "    resets = []\n",
        "\n",
        "    # Aplicando a compressão LZW, considerando cada byte do arquivo original como um símbolo de entrada\n",
        "    try:\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        while (byte := file.read(1)):\n",
        "          symbol = bin(int.from_bytes(byte, \"big\"))[2:].zfill(8)\n",
        "\n",
        "          string_plus_symbol = string + symbol\n",
        "\n",
        "          if dictionary.search(string_plus_symbol) != None:\n",
        "              string = string_plus_symbol\n",
        "          else:\n",
        "            # Reiniciando o dicionário no algoritmo estático\n",
        "            if(compression_type == \"s\"):\n",
        "              if(dict_size == dict_size_limit - 1):\n",
        "                reset = True\n",
        "            # Expandindo os códigos no algoritmo dinâmico (até o limite)\n",
        "            else:\n",
        "              if(dict_size == (2 ** codes_max_size) - 1):\n",
        "                reset = True\n",
        "              else:\n",
        "                if(dict_size == next_dict_size_limit):\n",
        "                    num_bits_values += 1\n",
        "                    next_dict_size_limit *= 2\n",
        "\n",
        "            current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "            compressed_data.append(current_string_formatted_binary_value)\n",
        "            new_key_value = bin(dict_size)[2:].zfill(num_bits_values)\n",
        "            dictionary.insert(string_plus_symbol, new_key_value)\n",
        "            dict_size += 1\n",
        "            string = symbol\n",
        "\n",
        "            if(reset):\n",
        "              reset = False\n",
        "              dict_size = 256\n",
        "\n",
        "              if(compression_type != \"s\"):\n",
        "                num_bits_values = 9\n",
        "                next_dict_size_limit = 512\n",
        "\n",
        "              dictionary = CompactTrie()\n",
        "              for num in range(256):\n",
        "                byte_num = format(num, '08b')\n",
        "                dictionary.insert(byte_num, byte_num)\n",
        "\n",
        "        if(dictionary.search(string) != None):\n",
        "          current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "          compressed_data.append(current_string_formatted_binary_value)\n",
        "\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError as e:\n",
        "      print(f\"Arquivo não encontrado -> {e}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Erro de I/O -> {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Um erro ocorreu: {e}\")\n",
        "\n",
        "    # Salvando o nome do arquivo original e sua extensão para que o arquivo de compressão possa ser salvo\n",
        "    file_name, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "    with open(f\"compressed_{file_name}.bin\", \"wb\") as file:\n",
        "      # Convertendo os códigos para uma única string\n",
        "      final_concat_string_data = ''.join(compressed_data)\n",
        "\n",
        "      # Verificando se algum padding deverá ser adicionado para que tenhamos um número inteiro de bytes no arquivo comprimido\n",
        "      padding_size = (8 - len(final_concat_string_data) % 8) % 8\n",
        "      final_concat_string_data = '0' * padding_size + final_concat_string_data\n",
        "\n",
        "      # Adicionando uma flag, no arquivo comprimido, para representar o tamanho do padding que foi adicionado\n",
        "      file.write(bytes([padding_size]))\n",
        "\n",
        "      # Convertendo a string de dados comprimidos para bytes e escrevendo no arquivo comprimido final\n",
        "      bits = []\n",
        "      for char in final_concat_string_data:\n",
        "        bits.append(1 if char == '1' else 0)\n",
        "      byte = 0\n",
        "      bit_count = 0\n",
        "      for bit in bits:\n",
        "        byte = (byte << 1) | bit\n",
        "        bit_count += 1\n",
        "        if bit_count == 8:\n",
        "          file.write(bytes([byte]))\n",
        "          byte = 0\n",
        "          bit_count = 0\n",
        "\n",
        "      return file_name, file_extension\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Realiza a descompressão LZW do arquivo passado como parâmetro\n",
        "  def decompress(self, file_path, compression_type, original_file_name, original_file_extension, codes_max_size) -> None:\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 0, 1, 10, 11, 100, ... até 11111111 no dicionário (sem padding), com respectivos valores sendo a própria chave (com padding)\n",
        "    for num in range(256):\n",
        "      numeric_key = bin(num)[2:]\n",
        "      numeric_key_8bit_value = format(num, '08b')\n",
        "      dictionary.insert(numeric_key, numeric_key_8bit_value)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\n",
        "    reset = False\n",
        "    if(compression_type == \"s\"):\n",
        "      decompression_size = 12 # Sempre puxaremos 12 bits do arquivo comprimido por vez no caso estático\n",
        "      dict_size_limit = 2 ** decompression_size # Os 12 bits serão suficientes para representar códigos de 000000000000 (0) até 111111111111 (4095)\n",
        "    else:\n",
        "      decompression_size = 9 # Começaremos puxando 9 bits do arquivo comprimido por vez\n",
        "      next_size_limit = 512 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\n",
        "\n",
        "    # Abrindo o arquivo já comprimido e convertendo seus bytes em uma única string\n",
        "    compressed_data = \"\"\n",
        "    try:\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        file_data = file.read()\n",
        "        compressed_data = ''.join(format(byte, '08b') for byte in file_data)\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError:\n",
        "      print(f\"File not found: {file_path}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Error reading the file: {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "    # Retirando os bits de padding do arquivo comprimido\n",
        "    padding_size = int(compressed_data[:8], 2)\n",
        "    compressed_data = compressed_data[(8 + padding_size):]\n",
        "\n",
        "    # Inicializando as variáveis que serão empregadas posteriormente\n",
        "    string = compressed_data[:decompression_size]\n",
        "    string = string[-8:]\n",
        "    compressed_data = compressed_data[decompression_size:]\n",
        "    decompressed_data = [string]\n",
        "\n",
        "    # Aplicando a descompressão LZW\n",
        "    while(len(compressed_data) > 0):\n",
        "        if(compression_type == \"s\"):\n",
        "          # Caso em que os códigos têm tamanho estático\n",
        "          if(dict_size == dict_size_limit - 1):\n",
        "            reset = True\n",
        "        else:\n",
        "          # Caso em que os códigos têm tamanho dinâmico\n",
        "          if(dict_size == 2 ** codes_max_size - 1):\n",
        "            reset = True\n",
        "          else:\n",
        "            if(dict_size == next_size_limit - 1):\n",
        "              decompression_size += 1\n",
        "              next_size_limit *= 2\n",
        "\n",
        "        k = compressed_data[:decompression_size]\n",
        "        compressed_data = compressed_data[decompression_size:]\n",
        "        k = remove_leading_zeros(k)\n",
        "\n",
        "        if dictionary.search(k) != None:\n",
        "          entry = dictionary.search(k).value\n",
        "        else:\n",
        "          new_value_entry_concat = string[:8]\n",
        "          entry = string + new_value_entry_concat\n",
        "\n",
        "        decompressed_data.append(entry)\n",
        "        new_key = bin(dict_size)[2:] if dict_size != 0 else '0'\n",
        "        dictionary.insert(new_key, string + entry[:8])\n",
        "        dict_size += 1\n",
        "        string = entry\n",
        "\n",
        "        if(reset):\n",
        "          reset = False\n",
        "          dict_size = 256\n",
        "\n",
        "          if(compression_type != \"s\"):\n",
        "            decompression_size = 9\n",
        "            next_size_limit = 512\n",
        "\n",
        "          dictionary = CompactTrie()\n",
        "          for num in range(256):\n",
        "            numeric_key = bin(num)[2:]\n",
        "            numeric_key_8bit_value = format(num, '08b')\n",
        "            dictionary.insert(numeric_key, numeric_key_8bit_value)\n",
        "\n",
        "    decompressed_concat_string = ''.join(decompressed_data)\n",
        "\n",
        "    # Checando algum possível erro que possa ter ocorrido na descompressão (o tamanho do arquivo final deve ser um múltiplo de 8)\n",
        "    if len(decompressed_concat_string) % 8 != 0:\n",
        "      raise ValueError(\"O arquivo descomprimido não tem um número inteiro de bytes!\")\n",
        "\n",
        "    # Transformando a string binárias em bytes individuais\n",
        "    byte_chunks = [decompressed_concat_string[i:i+8] for i in range(0, len(decompressed_concat_string), 8)]\n",
        "    bytes_ = [int(chunk, 2) for chunk in byte_chunks]\n",
        "\n",
        "    # Convert integers to their ASCII characters\n",
        "    ascii_characters = [chr(i) for i in bytes_]\n",
        "    # Join characters into a string (optional)\n",
        "    ascii_string = ''.join(ascii_characters)\n",
        "\n",
        "    # Gerando o arquivo inicial\n",
        "    switch = {\n",
        "        '.txt': write_txt_file,\n",
        "        '.bmp': write_image_file,\n",
        "        '.tiff': write_image_file # Não sei se está funcionando\n",
        "        }\n",
        "    handler = switch.get(original_file_extension)\n",
        "    if handler:\n",
        "        handler(bytes_, f\"decompressed_{original_file_name}{original_file_extension}\")\n",
        "    else:\n",
        "        print(\"Tipo de arquivo não suportado!\")"
      ],
      "metadata": {
        "id": "SuY2NIhY8vFg"
      },
      "execution_count": 1118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fazendo a compressão e a descompressão de arquivos usando a classe TrieLZW:"
      ],
      "metadata": {
        "id": "mmZHM1wtffn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Função temporária para verificar se dois arquivos são iguais:"
      ],
      "metadata": {
        "id": "1xCgIMdnIFn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def are_files_identical(file1, file2):\n",
        "    \"\"\"\n",
        "    Compare two files byte by byte to check if they are identical.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file1, \"rb\") as f1, open(file2, \"rb\") as f2:\n",
        "            while True:\n",
        "                chunk1 = f1.read(4096)  # Read in chunks of 4 KB\n",
        "                chunk2 = f2.read(4096)\n",
        "                if chunk1 != chunk2:  # Compare the current chunks\n",
        "                    return False\n",
        "                if not chunk1:  # End of file reached\n",
        "                    return True\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "FY9kGlKUIFIz"
      },
      "execution_count": 1135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def are_files_identical(file1, file2):\n",
        "    \"\"\"\n",
        "    Compare two files byte by byte to check if they are identical and find the position of the first difference.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file1, \"rb\") as f1, open(file2, \"rb\") as f2:\n",
        "            position = 0  # Track the byte position\n",
        "            while True:\n",
        "                chunk1 = f1.read(4096)  # Read in chunks of 4 KB\n",
        "                chunk2 = f2.read(4096)\n",
        "\n",
        "                # Check if chunks differ\n",
        "                if chunk1 != chunk2:\n",
        "                    # Find exact byte within the differing chunk\n",
        "                    for i in range(len(chunk1)):\n",
        "                        if i >= len(chunk2) or chunk1[i] != chunk2[i]:\n",
        "                            print(position + i)\n",
        "                            return  # Return the exact byte position\n",
        "\n",
        "                # If no data is left in both files, they're identical\n",
        "                if not chunk1:\n",
        "                    pass  # Files are identical\n",
        "\n",
        "                position += len(chunk1)  # Update position\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "HED42ithIVqA",
        "outputId": "153eb6b2-9d33-4e30-d1e3-0e5615b1c186"
      },
      "execution_count": 1120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef are_files_identical(file1, file2):\\n    \"\"\"\\n    Compare two files byte by byte to check if they are identical and find the position of the first difference.\\n    \"\"\"\\n    try:\\n        with open(file1, \"rb\") as f1, open(file2, \"rb\") as f2:\\n            position = 0  # Track the byte position\\n            while True:\\n                chunk1 = f1.read(4096)  # Read in chunks of 4 KB\\n                chunk2 = f2.read(4096)\\n\\n                # Check if chunks differ\\n                if chunk1 != chunk2:\\n                    # Find exact byte within the differing chunk\\n                    for i in range(len(chunk1)):\\n                        if i >= len(chunk2) or chunk1[i] != chunk2[i]:\\n                            print(position + i)\\n                            return  # Return the exact byte position\\n\\n                # If no data is left in both files, they\\'re identical\\n                if not chunk1:\\n                    pass  # Files are identical\\n\\n                position += len(chunk1)  # Update position\\n\\n    except FileNotFoundError as e:\\n        print(f\"Error: {e}\")\\n        return None\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 1 (arquivo de texto)"
      ],
      "metadata": {
        "id": "j1DNUBiQFIEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerando artificialmente um texto para teste:"
      ],
      "metadata": {
        "id": "N3gY71UFGNqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "# Generate the random text\n",
        "input_data = ''.join(random.choices(\"abcd\", k=100000))\n",
        "\n",
        "# Specify the file path\n",
        "file_path = \"test_text.txt\"\n",
        "if os.path.exists(file_path):\n",
        "      os.remove(file_path)\n",
        "\n",
        "# Save the text to a .txt file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(input_data)"
      ],
      "metadata": {
        "id": "FDykAeJ8GoZI"
      },
      "execution_count": 1121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando a compressão e a descompressão em sequência:"
      ],
      "metadata": {
        "id": "W2gy7nClHEf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teste_trie_lzw = TrieLZW()\n",
        "\n",
        "file_to_be_compressed = \"test_text.txt\"\n",
        "\n",
        "(file_name, file_extension) = teste_trie_lzw.compress(file_to_be_compressed, \"d\", 11)\n",
        "\n",
        "compressed_file = f\"compressed_{file_name}.bin\"\n",
        "\n",
        "teste_trie_lzw.decompress(compressed_file, \"d\", file_name, file_extension, 11)"
      ],
      "metadata": {
        "id": "A9FAan1JHEvg",
        "collapsed": true
      },
      "execution_count": 1133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando o tamanho dos arquivos iniciais e finais:"
      ],
      "metadata": {
        "id": "vq-qVz1JHND5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_file_size = os.path.getsize(file_to_be_compressed)\n",
        "compressed_file_size = os.path.getsize(compressed_file)\n",
        "\n",
        "print(f\"Tamanho do arquivo original: {original_file_size} bytes.\")\n",
        "print(f\"Tamanho do arquivo comprimido: {compressed_file_size} bytes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVQ17h5hHNam",
        "outputId": "fb888c95-0e66-44bc-f3fd-01e2c2f411f4"
      },
      "execution_count": 1136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do arquivo original: 100000 bytes.\n",
            "Tamanho do arquivo comprimido: 31156 bytes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se os arquivos são equivalentes:"
      ],
      "metadata": {
        "id": "xxaprA7qIKI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt_file1 = file_to_be_compressed\n",
        "txt_file2 = f\"decompressed_{file_to_be_compressed}\"\n",
        "print(txt_file1)\n",
        "print(txt_file2)\n",
        "print(f\"Os arquivos .txt são iguais? {are_files_identical(txt_file1, txt_file2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPXmewVOH3zY",
        "outputId": "d3d3a866-09f1-48fe-9a09-f0dd6a0bf970"
      },
      "execution_count": 1137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_text.txt\n",
            "decompressed_test_text.txt\n",
            "Os arquivos .txt são iguais? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 2 (arquivo de imagem)"
      ],
      "metadata": {
        "id": "DmRmH2ByF57b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerando artificialmente uma imagem para teste:"
      ],
      "metadata": {
        "id": "xXx45HefE6Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Create a new monochrome (mode '1') image with 10x10 pixels\n",
        "width, height = 1000, 1000\n",
        "image = Image.new(\"1\", (width, height))  # Mode \"1\" means 1-bit pixels (monochrome)\n",
        "\n",
        "# Set some pixels to black (1 = white, 0 = black)\n",
        "pixels = image.load()\n",
        "for x in range(width):\n",
        "    for y in range(height):\n",
        "        if (x + y) % 2 == 0:  # Example pattern: checkerboard\n",
        "            pixels[x, y] = 0  # Black pixel\n",
        "        else:\n",
        "            pixels[x, y] = 1  # White pixel\n",
        "\n",
        "# Save the image as a BMP file\n",
        "image.save(\"monochrome_test_image.bmp\")"
      ],
      "metadata": {
        "id": "xn3RDWTVETTH"
      },
      "execution_count": 1125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando a compressão e a descompressão em sequência:"
      ],
      "metadata": {
        "id": "euSnTsx0GDau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teste_trie_lzw = TrieLZW()\n",
        "\n",
        "file_to_be_compressed = \"monochrome_test_image.bmp\"\n",
        "\n",
        "(file_name, file_extension) = teste_trie_lzw.compress(file_to_be_compressed, \"d\", 11)\n",
        "\n",
        "compressed_file = f\"compressed_{file_name}.bin\"\n",
        "\n",
        "teste_trie_lzw.decompress(compressed_file, \"d\", file_name, file_extension, 11)"
      ],
      "metadata": {
        "id": "4jAYNs6mfjyT"
      },
      "execution_count": 1126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando o tamanho dos arquivos iniciais e finais:"
      ],
      "metadata": {
        "id": "c_QpZq3kDbtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_file_size = os.path.getsize(file_to_be_compressed)\n",
        "compressed_file_size = os.path.getsize(compressed_file)\n",
        "\n",
        "print(f\"Tamanho do arquivo original: {original_file_size} bytes.\")\n",
        "print(f\"Tamanho do arquivo comprimido: {compressed_file_size} bytes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHQ4te_yCXLH",
        "outputId": "ab414cfd-c60e-4356-e882-0529260bf9cd"
      },
      "execution_count": 1127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do arquivo original: 128062 bytes.\n",
            "Tamanho do arquivo comprimido: 2937 bytes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se os arquivos são equivalentes:"
      ],
      "metadata": {
        "id": "NMYnnNwsISgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bmp_file1 = file_to_be_compressed\n",
        "bmp_file2 = f\"decompressed_{file_to_be_compressed}\"\n",
        "\n",
        "print(f\"Os arquivos .bmp são iguais? {are_files_identical(bmp_file1, bmp_file2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUwbzZT6IPsG",
        "outputId": "3593450d-cf07-4706-cb78-7543fba104ac"
      },
      "execution_count": 1128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Os arquivos .bmp são iguais? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seção provisória para debug"
      ],
      "metadata": {
        "id": "W0AHGnxlDQKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import struct\n",
        "\n",
        "def int_to_8bit_binary(number):\n",
        "  return format(number, '08b')\n",
        "\n",
        "def remove_leading_zeros(binary_str):\n",
        "  return binary_str.lstrip('0') or '0'\n",
        "\n",
        "class LZW:\n",
        "    def __init__(self):\n",
        "        self.max_table_size = 4096\n",
        "\n",
        "    def compress(self, input_data):\n",
        "        dictionary = {chr(i): i for i in range(256)}\n",
        "        string = \"\"\n",
        "        compressed_data = []\n",
        "\n",
        "        for symbol in input_data:\n",
        "            string_plus_symbol = string + symbol\n",
        "            if string_plus_symbol in dictionary:\n",
        "                string = string_plus_symbol\n",
        "            else:\n",
        "                compressed_data.append(dictionary[string])\n",
        "                if len(dictionary) < self.max_table_size:\n",
        "                    dictionary[string_plus_symbol] = len(dictionary)\n",
        "                string = symbol\n",
        "\n",
        "        if string in dictionary:\n",
        "            compressed_data.append(dictionary[string])\n",
        "\n",
        "        return compressed_data\n",
        "\n",
        "    def decompress(self, compressed_data):\n",
        "        dictionary = {chr(i): i for i in range(256)}\n",
        "        string = chr(compressed_data.pop(0))\n",
        "        decompressed_data = [string]\n",
        "\n",
        "        for k in compressed_data:\n",
        "            print(k)\n",
        "            if k in dictionary:\n",
        "                entry = dictionary[k]\n",
        "            elif k == len(dictionary):\n",
        "                entry = string + string[0]\n",
        "            else:\n",
        "                raise ValueError(\"Erro na compressão k: %s\" % k)\n",
        "\n",
        "            decompressed_data.append(entry)\n",
        "\n",
        "            if len(dictionary) < self.max_table_size:\n",
        "                dictionary[len(dictionary)] = string + entry[0]\n",
        "\n",
        "            string = entry\n",
        "\n",
        "        return ''.join(decompressed_data)"
      ],
      "metadata": {
        "id": "dJYdN1_XzR4F"
      },
      "execution_count": 1129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "import random\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    lzw = LZW()\n",
        "\n",
        "    input_data = ''.join(random.choices(\"ab\", k=1000))\n",
        "\n",
        "    input_data = 'geekific-geekific'\n",
        "\n",
        "    with open(\"input.txt\", 'w') as file:\n",
        "      file.write(input_data)\n",
        "\n",
        "    with open(\"input.txt\", \"r\") as file:\n",
        "      input_data = file.read()\n",
        "\n",
        "    with open('input.txt', 'rb') as file:\n",
        "      input_data_2 = file.read()\n",
        "      input_data_2 = list(input_data_2)\n",
        "\n",
        "    compressed_data = lzw.compress(input_data)\n",
        "    #compressed_data_trie = lzw.compress_trie(input_data_2)\n",
        "    #integer_compressed_data_trie = [int(binary, 2) for binary in compressed_data_trie]\n",
        "\n",
        "    #print(\"A compressão ficou igual!\") if compressed_data == integer_compressed_data_trie else print(\"A compressão ficou diferente!\")\n",
        "    print(\"Arquivo comprimido (dict):\", compressed_data)\n",
        "    #print(\"Arquivo comprimido (trie):\", integer_compressed_data_trie)\n",
        "    #print(\"Arquivo comprimido original (trie):\", compressed_data_trie)\n",
        "\n",
        "    with open(\"text_compressed_result.txt\", 'w') as file:\n",
        "      final_compressed_string = ''.join(compressed_data_trie)\n",
        "      file.write(final_compressed_string)\n",
        "\n",
        "    with open(\"binary_compressed_result.bin\", 'wb') as file:\n",
        "      final_compressed_string = ''.join(compressed_data_trie)\n",
        "\n",
        "      padding_size = (8 - len(final_compressed_string) % 8) % 8\n",
        "      final_compressed_string = '0' * padding_size + final_compressed_string\n",
        "\n",
        "      file.write(bytes([padding_size]))\n",
        "\n",
        "      bits = []\n",
        "      for char in final_compressed_string:\n",
        "          bits.append(1 if char == '1' else 0)\n",
        "\n",
        "      byte = 0\n",
        "      bit_count = 0\n",
        "      for bit in bits:\n",
        "          byte = (byte << 1) | bit\n",
        "          bit_count += 1\n",
        "\n",
        "          if bit_count == 8:\n",
        "              file.write(bytes([byte]))\n",
        "              byte = 0\n",
        "              bit_count = 0\n",
        "\n",
        "    size_file1 = os.path.getsize(\"input.txt\")\n",
        "    size_file2 = os.path.getsize(\"binary_compressed_result.bin\")\n",
        "\n",
        "    with open(\"binary_compressed_result.bin\", 'rb') as file:\n",
        "      padding_size = ord(file.read(1))\n",
        "\n",
        "      data = file.read()\n",
        "\n",
        "      binary_string = ''.join(format(byte, '08b') for byte in data)\n",
        "\n",
        "      binary_string = binary_string[padding_size:]\n",
        "\n",
        "    result = lzw.decompress_trie(binary_string)\n",
        "\n",
        "    print(\" O resultado antes da compressão é: \" + input_data)\n",
        "    print(\"O resultado após a descompressão é: \" + result)\n",
        "    print(f\"Tamanho do arquivo original: {size_file1} bytes\")\n",
        "    print(f\"Tamanho do arquivo comprimido: {size_file2} bytes\")\n",
        "    print(\"O LZW foi bem-sucedido!\") if result == input_data else print(\"O LZW não foi bem-sucedido!\")\n",
        "\n",
        "    with open(\"compressed_binary.txt\", \"w\") as file:\n",
        "        binary_data = ' '.join(format(data, '012b') for data in compressed_data)\n",
        "        file.write(binary_data)\n",
        "\n",
        "    decompressed_data = lzw.decompress(compressed_data)\n",
        "    print(\"Arquivo descomprimido:\", decompressed_data)\n",
        "\n",
        "    with open(\"decompressed.txt\", \"w\") as file:\n",
        "        file.write(decompressed_data)\n",
        "    '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5YRTsawOvp5n",
        "outputId": "c7367d80-080e-4c9f-8b67-29e438664dc2"
      },
      "execution_count": 1130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nimport random\\n\\nif __name__ == \"__main__\":\\n    lzw = LZW()\\n\\n    input_data = \\'\\'.join(random.choices(\"ab\", k=1000))\\n\\n    input_data = \\'geekific-geekific\\'\\n\\n    with open(\"input.txt\", \\'w\\') as file:\\n      file.write(input_data)\\n\\n    with open(\"input.txt\", \"r\") as file:\\n      input_data = file.read()\\n\\n    with open(\\'input.txt\\', \\'rb\\') as file:\\n      input_data_2 = file.read()\\n      input_data_2 = list(input_data_2)\\n\\n    compressed_data = lzw.compress(input_data)\\n    #compressed_data_trie = lzw.compress_trie(input_data_2)\\n    #integer_compressed_data_trie = [int(binary, 2) for binary in compressed_data_trie]\\n\\n    #print(\"A compressão ficou igual!\") if compressed_data == integer_compressed_data_trie else print(\"A compressão ficou diferente!\")\\n    print(\"Arquivo comprimido (dict):\", compressed_data)\\n    #print(\"Arquivo comprimido (trie):\", integer_compressed_data_trie)\\n    #print(\"Arquivo comprimido original (trie):\", compressed_data_trie)\\n\\n    with open(\"text_compressed_result.txt\", \\'w\\') as file:\\n      final_compressed_string = \\'\\'.join(compressed_data_trie)\\n      file.write(final_compressed_string)\\n\\n    with open(\"binary_compressed_result.bin\", \\'wb\\') as file:\\n      final_compressed_string = \\'\\'.join(compressed_data_trie)\\n\\n      padding_size = (8 - len(final_compressed_string) % 8) % 8\\n      final_compressed_string = \\'0\\' * padding_size + final_compressed_string\\n\\n      file.write(bytes([padding_size]))\\n\\n      bits = []\\n      for char in final_compressed_string:\\n          bits.append(1 if char == \\'1\\' else 0)\\n\\n      byte = 0\\n      bit_count = 0\\n      for bit in bits:\\n          byte = (byte << 1) | bit\\n          bit_count += 1\\n\\n          if bit_count == 8:\\n              file.write(bytes([byte]))\\n              byte = 0\\n              bit_count = 0\\n\\n    size_file1 = os.path.getsize(\"input.txt\")\\n    size_file2 = os.path.getsize(\"binary_compressed_result.bin\")\\n\\n    with open(\"binary_compressed_result.bin\", \\'rb\\') as file:\\n      padding_size = ord(file.read(1))\\n\\n      data = file.read()\\n\\n      binary_string = \\'\\'.join(format(byte, \\'08b\\') for byte in data)\\n\\n      binary_string = binary_string[padding_size:]\\n\\n    result = lzw.decompress_trie(binary_string)\\n\\n    print(\" O resultado antes da compressão é: \" + input_data)\\n    print(\"O resultado após a descompressão é: \" + result)\\n    print(f\"Tamanho do arquivo original: {size_file1} bytes\")\\n    print(f\"Tamanho do arquivo comprimido: {size_file2} bytes\")\\n    print(\"O LZW foi bem-sucedido!\") if result == input_data else print(\"O LZW não foi bem-sucedido!\")\\n\\n    with open(\"compressed_binary.txt\", \"w\") as file:\\n        binary_data = \\' \\'.join(format(data, \\'012b\\') for data in compressed_data)\\n        file.write(binary_data)\\n\\n    decompressed_data = lzw.decompress(compressed_data)\\n    print(\"Arquivo descomprimido:\", decompressed_data)\\n\\n    with open(\"decompressed.txt\", \"w\") as file:\\n        file.write(decompressed_data)\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "from IPython.display import Image\n",
        "from random import choice\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "trie = CompactTrie()\n",
        "\n",
        "k = bin(0)[2:]\n",
        "v = format(0, '08b')\n",
        "\n",
        "trie.insert(k, v)\n",
        "\n",
        "file_path = \"interactive_trie.png\"\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "    print(f\"{file_path} has been deleted.\")\n",
        "else:\n",
        "    print(f\"{file_path} does not exist.\")\n",
        "trie.visualize(\"interactive_trie\")\n",
        "display(Image(filename=\"interactive_trie.png\"))\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "esCMZ8v7RSON",
        "outputId": "21a438f7-2bcd-407b-b7de-abf49c3327be"
      },
      "execution_count": 1131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nfrom IPython.display import Image\\nfrom random import choice\\nfrom IPython.display import display, clear_output\\nimport ipywidgets as widgets\\n\\ntrie = CompactTrie()\\n\\nk = bin(0)[2:]\\nv = format(0, \\'08b\\')\\n\\ntrie.insert(k, v)\\n\\nfile_path = \"interactive_trie.png\"\\nif os.path.exists(file_path):\\n    os.remove(file_path)\\n    print(f\"{file_path} has been deleted.\")\\nelse:\\n    print(f\"{file_path} does not exist.\")\\ntrie.visualize(\"interactive_trie\")\\ndisplay(Image(filename=\"interactive_trie.png\"))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import Image\n",
        "from random import choice\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "trie = CompactTrie()\n",
        "global_counter = 0\n",
        "delete_input = widgets.Text(description=\"Delete:\")\n",
        "delete_button = widgets.Button(description=\"Delete String\")\n",
        "\n",
        "def reset_trie(_):\n",
        "    global trie, global_counter\n",
        "    trie = CompactTrie()\n",
        "    global_counter = 0\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    auto_button = widgets.Button(description=\"Auto\")\n",
        "    auto_button.on_click(random_insert)\n",
        "    display(auto_button)\n",
        "\n",
        "def random_insert(_):\n",
        "    global global_counter\n",
        "    global_counter += 1\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    iterate_button = widgets.Button(description=\"Next Iteration\")\n",
        "    iterate_button.on_click(random_insert)\n",
        "    display(iterate_button)\n",
        "\n",
        "    delete_button.on_click(delete_string)\n",
        "    display(delete_input)\n",
        "    display(delete_button)\n",
        "\n",
        "    reset_button = widgets.Button(description=\"Reset Trie\")\n",
        "    reset_button.on_click(reset_trie)\n",
        "    display(reset_button)\n",
        "\n",
        "    new_node_string = ''.join(choice(['a', 'b']) for _ in range(6))\n",
        "    print(f\"Generated string: {new_node_string}\")\n",
        "\n",
        "    new_binary_string = ''.join('0' if char == 'a' else '1' for char in new_node_string)\n",
        "\n",
        "    trie.insert(new_binary_string, global_counter)\n",
        "\n",
        "    file_path = \"interactive_trie.png\"\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        print(f\"{file_path} has been deleted.\")\n",
        "    else:\n",
        "        print(f\"{file_path} does not exist.\")\n",
        "\n",
        "    trie.visualize(\"interactive_trie\")\n",
        "\n",
        "    display(Image(filename=\"interactive_trie.png\"))\n",
        "\n",
        "def delete_string(_):\n",
        "    global delete_input\n",
        "    binary_string = delete_input.value.strip()\n",
        "    new_binary_string = ''.join('0' if char == 'a' else '1' for char in binary_string)\n",
        "    trie.delete_key(new_binary_string)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    iterate_button = widgets.Button(description=\"Next Iteration\")\n",
        "    iterate_button.on_click(random_insert)\n",
        "    display(iterate_button)\n",
        "\n",
        "    delete_button.on_click(delete_string)\n",
        "    display(delete_input)\n",
        "    display(delete_button)\n",
        "\n",
        "    reset_button = widgets.Button(description=\"Reset Trie\")\n",
        "    reset_button.on_click(reset_trie)\n",
        "    display(reset_button)\n",
        "\n",
        "    file_path = \"interactive_trie.png\"\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        print(f\"{file_path} has been deleted.\")\n",
        "    else:\n",
        "        print(f\"{file_path} does not exist.\")\n",
        "\n",
        "    trie.visualize(\"interactive_trie\")\n",
        "\n",
        "    display(Image(filename=\"interactive_trie.png\"))\n",
        "\n",
        "auto_button = widgets.Button(description=\"Auto\")\n",
        "auto_button.on_click(random_insert)\n",
        "display(auto_button)"
      ],
      "metadata": {
        "id": "kvvKGx9OODL4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69,
          "referenced_widgets": [
            "d145359c4f9e4658ae6618ddb61020a4",
            "ed212259f21a4803a759441455449ddd",
            "24b80722b0fb4a5aa6fb9354b4481496"
          ]
        },
        "outputId": "8873a259-39f1-4bc0-acbd-b0538a447754"
      },
      "execution_count": 1132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(description='Auto', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d145359c4f9e4658ae6618ddb61020a4"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}