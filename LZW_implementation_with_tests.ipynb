{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QdirNd4QFY_B",
        "tPUXHOt-Fg46",
        "1xCgIMdnIFn2",
        "DmRmH2ByF57b",
        "W0AHGnxlDQKE"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gustavochavesferreira/tp1_algoritmos2/blob/main/LZW_implementation_with_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Instalações provisórias para debug"
      ],
      "metadata": {
        "id": "QdirNd4QFY_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz\n",
        "!apt-get install graphviz -y\n",
        "\n",
        "from graphviz import Digraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frdzrsj6KUqW",
        "outputId": "827e54f8-ae57-445e-8366-e579d4eb7e4c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.42.2-6ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação da árvore de prefixos (Trie)"
      ],
      "metadata": {
        "id": "tPUXHOt-Fg46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementando a versão final da compressão LZW, empregando árvores Trie como dicionários para consulta e inserção:"
      ],
      "metadata": {
        "id": "7Eg8GeDbe6xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile lzw.py\n",
        "\n",
        "import os\n",
        "from typing import Tuple\n",
        "import struct\n",
        "\n",
        "import time\n",
        "import tracemalloc\n",
        "import json\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "class CompactTrieNode:\n",
        "  def __init__(self, binary_string: str = \"\", value: str = \"\", is_leaf: bool = False) -> None:\n",
        "    self.children = [None, None]\n",
        "    self.is_leaf = is_leaf\n",
        "    self.binary_string = binary_string\n",
        "    self.value = value\n",
        "    self.unique_id = id(self)  # Temporário\n",
        "\n",
        "class CompactTrie:\n",
        "  def __init__(self) -> None:\n",
        "    self.root = None\n",
        "\n",
        "  def get_common_prefix_length(self, key1: str, key2: str) -> int:\n",
        "    i = 0\n",
        "    while i < min(len(key1), len(key2)) and key1[i] == key2[i]:\n",
        "        i += 1\n",
        "    return i\n",
        "\n",
        "  def search(self, key: str) -> CompactTrieNode:\n",
        "    current_node = self.root\n",
        "\n",
        "    if(current_node == None):\n",
        "      return None\n",
        "\n",
        "    while True:\n",
        "      if((current_node.binary_string == key) and (current_node.is_leaf == True)):\n",
        "        return current_node\n",
        "\n",
        "      common_prefix_length = self.get_common_prefix_length(current_node.binary_string, key)\n",
        "\n",
        "      if(common_prefix_length == len(current_node.binary_string)):\n",
        "\n",
        "        key = key[common_prefix_length:]\n",
        "\n",
        "        if current_node.children[int(key[0])] == None:\n",
        "          return None\n",
        "\n",
        "        current_node = current_node.children[int(key[0])]\n",
        "      else:\n",
        "        return None\n",
        "\n",
        "  def insert(self, key: str, value: str) -> None:\n",
        "    # Caso em que não tínhamos raiz\n",
        "    if(self.root == None):\n",
        "      self.root = CompactTrieNode(key, value, True)\n",
        "      return\n",
        "\n",
        "    else:\n",
        "      current_node = self.root\n",
        "\n",
        "      while True:\n",
        "        # Achei, posso parar\n",
        "        if(current_node.binary_string == key):\n",
        "          current_node.is_leaf = True\n",
        "          return\n",
        "\n",
        "        common_prefix_length = self.get_common_prefix_length(current_node.binary_string, key)\n",
        "\n",
        "        # Sobrou parte da key ainda, com certeza\n",
        "        if (common_prefix_length == len(current_node.binary_string)):\n",
        "          key = key[common_prefix_length:]\n",
        "\n",
        "          if current_node.children[int(key[0])] == None:\n",
        "            current_node.children[int(key[0])] = CompactTrieNode(key, value, True)\n",
        "            return\n",
        "\n",
        "          current_node = current_node.children[int(key[0])]\n",
        "\n",
        "        # Achei onde vou ter que criar novo nó para inserir\n",
        "        else:\n",
        "          key = key[common_prefix_length:]\n",
        "\n",
        "          if(current_node.is_leaf == True):\n",
        "            old_suffix_node = CompactTrieNode(current_node.binary_string[common_prefix_length:], current_node.value, True)\n",
        "          else:\n",
        "            old_suffix_node = CompactTrieNode(current_node.binary_string[common_prefix_length:], current_node.value)\n",
        "\n",
        "          old_suffix_node.children[0] = current_node.children[0]\n",
        "          old_suffix_node.children[1] = current_node.children[1]\n",
        "\n",
        "          current_node.binary_string = current_node.binary_string[:common_prefix_length]\n",
        "\n",
        "          if(len(key) > 0):\n",
        "            key_suffix_node = CompactTrieNode(key, value, True)\n",
        "            current_node.is_leaf = False\n",
        "            current_node.children[int(key_suffix_node.binary_string[0])] = key_suffix_node\n",
        "            current_node.children[int(old_suffix_node.binary_string[0])] = old_suffix_node\n",
        "          else:\n",
        "            current_node.value = value\n",
        "            current_node.is_leaf = True\n",
        "            current_node.children = [None, None]\n",
        "            current_node.children[int(old_suffix_node.binary_string[0])] = old_suffix_node\n",
        "          return\n",
        "\n",
        "  def delete_key(self, key: str) -> None:\n",
        "    if(self.search(key) == None):\n",
        "      return\n",
        "\n",
        "    current_node = self.root\n",
        "    last_node = self.root\n",
        "\n",
        "    if(current_node.binary_string == key):\n",
        "      if(current_node.children[0] == None and current_node.children[1] == None):\n",
        "        self.root = None\n",
        "        return\n",
        "      elif(current_node.children[0] != None and current_node.children[1] != None):\n",
        "        current_node.is_leaf = False\n",
        "        return\n",
        "      else:\n",
        "        valid_child = 0 if current_node.children[0] != None else 1\n",
        "        current_node.children[valid_child].binary_string = current_node.binary_string + current_node.children[valid_child].binary_string\n",
        "        self.root = current_node.children[valid_child]\n",
        "        return\n",
        "\n",
        "    while True:\n",
        "      if((current_node.binary_string == key) and (current_node.is_leaf == True)):\n",
        "        if((current_node.children[0] != None) and (current_node.children[1] != None)):\n",
        "          current_node.is_leaf = False\n",
        "        elif((current_node.children[0] == None) and (current_node.children[1] == None)):\n",
        "          last_node.children[int(current_node.binary_string[0])] = None\n",
        "\n",
        "          if(last_node.is_leaf == False):\n",
        "            last_node_other_child = 0 if current_node.binary_string[0] == '1' else 1\n",
        "\n",
        "            if(last_node.children[last_node_other_child] != None):\n",
        "              last_node.binary_string += last_node.children[last_node_other_child].binary_string\n",
        "              last_node.value = last_node.children[last_node_other_child].value\n",
        "              if(last_node.children[last_node_other_child].is_leaf):\n",
        "                last_node.is_leaf = True\n",
        "              last_node.children = last_node.children[last_node_other_child].children\n",
        "        else:\n",
        "          valid_child = 0 if current_node.children[0] != None else 1\n",
        "          current_node.children[valid_child].binary_string = current_node.binary_string + current_node.children[valid_child].binary_string\n",
        "          last_node.children[int(current_node.children[valid_child].binary_string[0])] = current_node.children[valid_child]\n",
        "        return\n",
        "\n",
        "      common_prefix_length = self.get_common_prefix_length(current_node.binary_string, key)\n",
        "      key = key[common_prefix_length:]\n",
        "      last_node = current_node\n",
        "      current_node = current_node.children[int(key[0])]\n",
        "\n",
        "  # Temporário\n",
        "  def visualize(self, filename=\"compact_trie\"):\n",
        "      dot = Digraph(comment=\"Compact Trie\")\n",
        "\n",
        "      def add_nodes_edges(node, parent_label=None):\n",
        "          if node is None:\n",
        "              return\n",
        "\n",
        "          new_node_binary_string = node.binary_string\n",
        "          new_node_binary_string = new_node_binary_string.replace(\"0\", \"a\")\n",
        "          new_node_binary_string = new_node_binary_string.replace(\"1\", \"b\")\n",
        "\n",
        "          node_label = f\"{new_node_binary_string}_{node.unique_id}\"\n",
        "\n",
        "          display_label = f\"{new_node_binary_string}\"\n",
        "          if(node.is_leaf):\n",
        "            display_label  += f\"\\\\nValue: {node.value}\"\n",
        "\n",
        "          dot.node(node_label, display_label, shape='circle', color='black', fontcolor='red' if node.is_leaf else 'blue')\n",
        "\n",
        "          if parent_label:\n",
        "              dot.edge(parent_label, node_label)\n",
        "          if node.children[0] is not None:\n",
        "              add_nodes_edges(node.children[0], node_label)\n",
        "          if node.children[1] is not None:\n",
        "              add_nodes_edges(node.children[1], node_label)\n",
        "\n",
        "      if self.root is not None:\n",
        "          add_nodes_edges(self.root)\n",
        "\n",
        "      dot.render(filename, format=\"png\", cleanup=True)\n",
        "      print(f\"Compact trie saved as {filename}.png\")\n",
        "\n",
        "# Para debug\n",
        "def binary_to_chars(binary_string):\n",
        "    # Ensure the binary string length is a multiple of 8 (since each character is 8 bits)\n",
        "    if len(binary_string) % 8 != 0:\n",
        "        raise ValueError(\"Binary string length must be a multiple of 8.\")\n",
        "\n",
        "    # Split the binary string into chunks of 8 bits\n",
        "    chars = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\n",
        "\n",
        "    # Convert each 8-bit binary chunk to its corresponding character\n",
        "    result = ''.join(chr(int(char, 2)) for char in chars)\n",
        "\n",
        "    return result\n",
        "\n",
        "# # Função para converter um conjunto de bytes em um '.txt'\n",
        "# def write_txt_file(decoded_bytes, output_file):\n",
        "#     decoded_string = ''.join([chr(byte) for byte in decoded_bytes])\n",
        "#     with open(output_file, 'w', encoding='utf-8') as file:\n",
        "#         file.write(decoded_string)\n",
        "\n",
        "def write_txt_file(decoded_bytes, output_file):\n",
        "    with open(output_file, 'wb') as file:\n",
        "        file.write(bytes(decoded_bytes))\n",
        "\n",
        "\n",
        "# Função para converter um conjunto de bytes em um '.bmp' ou '.tiff'\n",
        "def write_image_file(decoded_bytes, output_file):\n",
        "    with open(output_file, 'wb') as file:\n",
        "        file.write(bytes(decoded_bytes))\n",
        "\n",
        "# Função para remover zeros à esquerda em uma string binárias\n",
        "def remove_leading_zeros(binary_str):\n",
        "  return binary_str.lstrip('0') or '0'\n",
        "\n",
        "\n",
        "class TrieLZW:\n",
        "  # Atributos para armazenar as estatísticas\n",
        "  def __init__(self):\n",
        "      self.stats = {\n",
        "          'compression_ratio_over_time': [],\n",
        "          'dictionary_size_over_time': [],\n",
        "          'execution_time': 0,\n",
        "          'memory_usage': 0\n",
        "      }\n",
        "\n",
        "  # Realiza a compressão LZW do arquivo passado como parâmetro\n",
        "  def compress(self, file_path: str=\"\") -> Tuple[str, str]:\n",
        "\n",
        "    # Iniciar rastreamento de tempo e memória\n",
        "    start_time = time.time()\n",
        "    tracemalloc.start()\n",
        "\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 00000000 até 11111111 no dicionário, com respectivos valores sendo a própria chave\n",
        "    for num in range(256):\n",
        "      byte_num = format(num, '08b')\n",
        "      dictionary.insert(byte_num, byte_num)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os símbolos ASCII\n",
        "    num_bits_values = 9 # Começaremos usando 9 bits para representar códigos a partir de agora\n",
        "    next_dict_size_limit = 2 * 256 # Os 9 bits serão suficientes para representar códigos de 000000000 (0) até 111111111 (511)\n",
        "\n",
        "    # Inicializando variáveis utilizadas pela compressão LZW\n",
        "    string = \"\"\n",
        "    compressed_data = []\n",
        "\n",
        "    # Aplicando a compressão LZW, considerando cada byte do arquivo orignal como um símbolo de entrada\n",
        "    try:\n",
        "      count = 256\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        while (byte := file.read(1)):\n",
        "          symbol = bin(int.from_bytes(byte, \"big\"))[2:].zfill(8)\n",
        "\n",
        "          string_plus_symbol = string + symbol\n",
        "\n",
        "          if dictionary.search(string_plus_symbol) != None:\n",
        "              string = string_plus_symbol\n",
        "          else:\n",
        "            # Caso em que o dicionário tem tamanho dinâmico\n",
        "            if(dict_size == next_dict_size_limit):\n",
        "                num_bits_values += 1\n",
        "                next_dict_size_limit *= 2\n",
        "\n",
        "            current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "            compressed_data.append(current_string_formatted_binary_value)\n",
        "            new_key_value = bin(dict_size)[2:].zfill(num_bits_values)\n",
        "            dictionary.insert(string_plus_symbol, new_key_value)\n",
        "            dict_size += 1\n",
        "            string = symbol\n",
        "\n",
        "\n",
        "            # Atualizar estatísticas\n",
        "            self.stats['dictionary_size_over_time'].append(dict_size)\n",
        "\n",
        "            # Calcular o tamanho comprimido atual (em bits)\n",
        "            compressed_size_bits = sum(len(code) for code in compressed_data)\n",
        "\n",
        "            # Calcular o tamanho original processado até agora (em bits)\n",
        "            original_size_bits = (len(compressed_data) + 1) * 8  # Cada símbolo original tem 8 bits\n",
        "\n",
        "            # Calcular a taxa de compressão atual\n",
        "            compression_ratio = compressed_size_bits / original_size_bits\n",
        "            self.stats['compression_ratio_over_time'].append(compression_ratio)\n",
        "\n",
        "\n",
        "        if(dictionary.search(string) != None):\n",
        "          current_string_formatted_binary_value = dictionary.search(string).value.zfill(num_bits_values)\n",
        "          compressed_data.append(current_string_formatted_binary_value)\n",
        "\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError as e:\n",
        "      print(f\"Arquivo não encontrado -> {e}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Erro de I/O -> {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Um erro ocorreu: {e}\")\n",
        "\n",
        "    # Salvando o nome do arquivo original e sua extensão para que o arquivo de compressão possa ser salvo\n",
        "    base_file_name = os.path.basename(file_path)\n",
        "    file_name_without_ext, file_extension = os.path.splitext(base_file_name)\n",
        "\n",
        "    # Nome do arquivo comprimido\n",
        "    compressed_file_name = f\"compressed_{file_name_without_ext}.bin\"\n",
        "    file_name = file_name_without_ext  # Add this line\n",
        "    # # Salvando o nome do arquivo original e sua extensão para que o arquivo de compressão possa ser salvo\n",
        "    # file_name, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "    with open(f\"compressed_{file_name}.bin\", \"wb\") as file:\n",
        "      # Convertendo os códigos para uma única string\n",
        "      final_concat_string_data = ''.join(compressed_data)\n",
        "\n",
        "      # Verificando se algum padding deverá ser adicionado para que tenhamos um número inteiro de bytes no arquivo comprimido\n",
        "      padding_size = (8 - len(final_concat_string_data) % 8) % 8\n",
        "      final_concat_string_data = '0' * padding_size + final_concat_string_data\n",
        "\n",
        "      # Adicionando uma flag, no arquivo comprimido, para representar o tamanho do padding que foi adicionado\n",
        "      file.write(bytes([padding_size]))\n",
        "\n",
        "      # Convertendo a string de dados comprimidos para bytes e escrevendo no arquivo comprimido final\n",
        "      bits = []\n",
        "      for char in final_concat_string_data:\n",
        "        bits.append(1 if char == '1' else 0)\n",
        "      byte = 0\n",
        "      bit_count = 0\n",
        "      for bit in bits:\n",
        "        byte = (byte << 1) | bit\n",
        "        bit_count += 1\n",
        "        if bit_count == 8:\n",
        "          file.write(bytes([byte]))\n",
        "          byte = 0\n",
        "          bit_count = 0\n",
        "\n",
        "      # Finalizar rastreamento de tempo e memória\n",
        "      end_time = time.time()\n",
        "      self.stats['execution_time'] = end_time - start_time\n",
        "\n",
        "      current_memory, peak_memory = tracemalloc.get_traced_memory()\n",
        "      self.stats['memory_usage'] = peak_memory / 1024  # Converter para KB\n",
        "      tracemalloc.stop()\n",
        "\n",
        "      return [file_name_without_ext, file_extension]\n",
        "\n",
        "  # Realiza a descompressão LZW do arquivo passado como parâmetro\n",
        "  def decompress(self, file_path: str=\"\", original_file_name: str=\"\", original_file_extension: str=\"\") -> None:\n",
        "\n",
        "    # Iniciar rastreamento de tempo e memória\n",
        "    start_time = time.time()\n",
        "    tracemalloc.start()\n",
        "\n",
        "    # Utilizando a Trie Compacta Binária como dicionário no algoritmo\n",
        "    dictionary = CompactTrie()\n",
        "\n",
        "    # Inicializando todas as chaves de 0, 1, 10, 11, 100, ... até 11111111 no dicionário (sem padding), com respectivos valores sendo a própria chave (com padding)\n",
        "    for num in range(256):\n",
        "      numeric_key = bin(num)[2:]\n",
        "      numeric_key_8bit_value = format(num, '08b')\n",
        "      dictionary.insert(numeric_key, numeric_key_8bit_value)\n",
        "\n",
        "    dict_size = 256 # O dicionário começa com todos os número de 0 até 255, cada um representando um símbolo ASCII\n",
        "    decompression_size = 9 # Começaremos puxando 9 bits do arquivo comprimido por vez\n",
        "    next_size_limit = 2 * 256 # Os 9 bits serão suficientes até que o tamanho do dicionário atinja 512 elementos\n",
        "\n",
        "    # Abrindo o arquivo já comprimido e convertendo seus bytes em uma única string\n",
        "    compressed_data = \"\"\n",
        "    try:\n",
        "      with open(file_path, \"rb\") as file:\n",
        "        file_data = file.read()\n",
        "        compressed_data = ''.join(format(byte, '08b') for byte in file_data)\n",
        "    # Tratando erros que podem ocorrer na abertura de um arquivo\n",
        "    except FileNotFoundError:\n",
        "      print(f\"File not found: {file_path}\")\n",
        "    except IOError as e:\n",
        "      print(f\"Error reading the file: {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "    # Retirando os bits de padding do arquivo comprimido\n",
        "    padding_size = int(compressed_data[:8], 2)\n",
        "    compressed_data = compressed_data[(8 + padding_size):]\n",
        "\n",
        "    # Inicializando as variáveis que serão empregadas posteriormente\n",
        "    string = compressed_data[:decompression_size]\n",
        "    string = string[-8:]\n",
        "\n",
        "    compressed_data = compressed_data[decompression_size:]\n",
        "    decompressed_data = [string]\n",
        "\n",
        "    # Aplicando a descompressão LZW\n",
        "    while(len(compressed_data) > 0):\n",
        "        # Caso em que o dicionário tem tamanho dinâmico\n",
        "        if(dict_size == next_size_limit - 1):\n",
        "          decompression_size += 1\n",
        "          next_size_limit *= 2\n",
        "\n",
        "        k = compressed_data[:decompression_size]\n",
        "        compressed_data = compressed_data[decompression_size:]\n",
        "\n",
        "        k = remove_leading_zeros(k)\n",
        "\n",
        "        if dictionary.search(k) != None:\n",
        "          entry = dictionary.search(k).value\n",
        "        else:\n",
        "          new_value_entry_concat = string[:8]\n",
        "          entry = string + new_value_entry_concat\n",
        "\n",
        "        decompressed_data.append(entry)\n",
        "        new_key = bin(dict_size)[2:] if dict_size != 0 else '0'\n",
        "        dictionary.insert(new_key, string + entry[:8])\n",
        "        dict_size += 1\n",
        "\n",
        "        string = entry\n",
        "\n",
        "    decompressed_concat_string = ''.join(decompressed_data)\n",
        "\n",
        "    # Checando algum possível erro que possa ter ocorrido na descompressão (o tamanho do arquivo final deve ser um múltiplo de 8)\n",
        "    if len(decompressed_concat_string) % 8 != 0:\n",
        "      raise ValueError(\"O arquivo descomprimido não tem um número inteiro de bytes!\")\n",
        "\n",
        "    # Transformando a string binárias em bytes individuais\n",
        "    byte_chunks = [decompressed_concat_string[i:i+8] for i in range(0, len(decompressed_concat_string), 8)]\n",
        "    bytes_ = [int(chunk, 2) for chunk in byte_chunks]\n",
        "\n",
        "    # Convert integers to their ASCII characters\n",
        "    ascii_characters = [chr(i) for i in bytes_]\n",
        "    # Join characters into a string (optional)\n",
        "    ascii_string = ''.join(ascii_characters)\n",
        "\n",
        "\n",
        "    # Nome do arquivo descomprimido\n",
        "    decompressed_file_name = f\"decompressed_{original_file_name}{original_file_extension}\"\n",
        "\n",
        "\n",
        "\n",
        "    # Gerando o arquivo inicial\n",
        "    switch = {\n",
        "        '.txt': write_txt_file,\n",
        "        '.bmp': write_image_file,\n",
        "        '.tiff': write_image_file,  # Não sei se está funcionando\n",
        "        '.bin': write_image_file    # Adicione esta linha\n",
        "\n",
        "    }\n",
        "    handler = switch.get(original_file_extension)\n",
        "    if handler:\n",
        "        handler(bytes_, decompressed_file_name)\n",
        "    else:\n",
        "        print(\"Unsupported file type.\")\n",
        "\n",
        "\n",
        "    # Finalizar rastreamento de tempo e memória\n",
        "    end_time = time.time()\n",
        "    self.stats['execution_time'] = end_time - start_time\n",
        "\n",
        "    current_memory, peak_memory = tracemalloc.get_traced_memory()\n",
        "    self.stats['memory_usage'] = peak_memory / 1024  # Converter para KB\n",
        "    tracemalloc.stop()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='Compress or decompress files using LZW algorithm with Compact Trie.')\n",
        "    subparsers = parser.add_subparsers(dest='command', help='Available commands: compress, decompress')\n",
        "\n",
        "    # Parser for the 'compress' command\n",
        "    compress_parser = subparsers.add_parser('compress', help='Compress a file')\n",
        "    compress_parser.add_argument('input_file', type=str, help='Path to the input file to compress')\n",
        "    compress_parser.add_argument('output_file', type=str, help='Path to the output compressed file')\n",
        "    compress_parser.add_argument('--max-bits', type=int, help='Maximum number of bits (default: 12)', default=12)\n",
        "    compress_parser.add_argument('--stats-file', type=str, help='Path to save compression stats', default=None)\n",
        "\n",
        "    # Parser for the 'decompress' command\n",
        "    decompress_parser = subparsers.add_parser('decompress', help='Decompress a file')\n",
        "    decompress_parser.add_argument('input_file', type=str, help='Path to the input compressed file')\n",
        "    decompress_parser.add_argument('output_file', type=str, help='Path to the output decompressed file')\n",
        "    decompress_parser.add_argument('--max-bits', type=int, help='Maximum number of bits (default: 12)', default=12)\n",
        "    decompress_parser.add_argument('--stats-file', type=str, help='Path to save decompression stats', default=None)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.command == 'compress':\n",
        "        compress(args.input_file, args.output_file, args.stats_file, args.max_bits)\n",
        "    elif args.command == 'decompress':\n",
        "        decompress(args.input_file, args.output_file, args.stats_file, args.max_bits)\n",
        "    else:\n",
        "        parser.print_help()\n",
        "\n",
        "def compress(input_file, output_file, stats_file=None, max_bits=12):\n",
        "    trie_lzw = TrieLZW()\n",
        "\n",
        "    # Executa a compressão\n",
        "    trie_lzw.compress(input_file)\n",
        "\n",
        "    # Obter o nome base do arquivo de entrada\n",
        "    input_base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
        "    compressed_file_name = f\"compressed_{input_base_name}.bin\"\n",
        "\n",
        "    if os.path.exists(compressed_file_name):\n",
        "        os.rename(compressed_file_name, output_file)\n",
        "    else:\n",
        "        print(f\"Error: Compressed file {compressed_file_name} not found.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Salva as estatísticas, se especificado\n",
        "    if stats_file:\n",
        "        with open(stats_file, 'w') as f:\n",
        "            json.dump(trie_lzw.stats, f, indent=4)\n",
        "        print(f\"Compression stats saved to {stats_file}\")\n",
        "\n",
        "    print(f\"Compression completed: {output_file}\")\n",
        "\n",
        "def decompress(input_file, output_file, stats_file=None, max_bits=12):\n",
        "    trie_lzw = TrieLZW()\n",
        "\n",
        "    # Obter o nome base e extensão do arquivo de saída\n",
        "    output_base_name, output_extension = os.path.splitext(os.path.basename(output_file))\n",
        "    original_file_name = output_base_name.replace('decompressed_', '')\n",
        "\n",
        "    # Executa a descompressão\n",
        "    trie_lzw.decompress(input_file, original_file_name, output_extension)\n",
        "\n",
        "    # Nome do arquivo descomprimido gerado pelo método\n",
        "    decompressed_file_name = f\"decompressed_{original_file_name}{output_extension}\"\n",
        "\n",
        "    if os.path.exists(decompressed_file_name):\n",
        "        os.rename(decompressed_file_name, output_file)\n",
        "    else:\n",
        "        print(f\"Error: Decompressed file {decompressed_file_name} not found.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Salva as estatísticas, se especificado\n",
        "    if stats_file:\n",
        "        with open(stats_file, 'w') as f:\n",
        "            json.dump(trie_lzw.stats, f, indent=4)\n",
        "        print(f\"Decompression stats saved to {stats_file}\")\n",
        "\n",
        "    print(f\"Decompression completed: {output_file}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v0kXszE43ECO",
        "outputId": "640708bd-e34b-48d6-fe19-ed4f5f22430a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] {compress,decompress} ...\n",
            "colab_kernel_launcher.py: error: argument command: invalid choice: '/root/.local/share/jupyter/runtime/kernel-cc27bb8d-2c81-433a-ac13-bef2b5a9201e.json' (choose from 'compress', 'decompress')\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 1878, in parse_known_args\n",
            "    namespace, args = self._parse_known_args(args, namespace)\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 2094, in _parse_known_args\n",
            "    stop_index = consume_positionals(start_index)\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 2050, in consume_positionals\n",
            "    take_action(action, args)\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 1939, in take_action\n",
            "    argument_values = self._get_values(action, argument_strings)\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 2484, in _get_values\n",
            "    self._check_value(action, value[0])\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 2531, in _check_value\n",
            "    raise ArgumentError(action, msg % args)\n",
            "argparse.ArgumentError: argument command: invalid choice: '/root/.local/share/jupyter/runtime/kernel-cc27bb8d-2c81-433a-ac13-bef2b5a9201e.json' (choose from 'compress', 'decompress')\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-22-324e0e799c96>\", line 553, in <cell line: 552>\n",
            "    main()\n",
            "  File \"<ipython-input-22-324e0e799c96>\", line 492, in main\n",
            "    args = parser.parse_args()\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 1845, in parse_args\n",
            "    args, argv = self.parse_known_args(args, namespace)\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 1881, in parse_known_args\n",
            "    self.error(str(err))\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 2606, in error\n",
            "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
            "  File \"/usr/lib/python3.10/argparse.py\", line 2593, in exit\n",
            "    _sys.exit(status)\n",
            "SystemExit: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1877\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1878\u001b[0;31m                 \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1879\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2093\u001b[0m         \u001b[0;31m# consume any positionals following the last Optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2094\u001b[0;31m         \u001b[0mstop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume_positionals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36mconsume_positionals\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   2049\u001b[0m                 \u001b[0mstart_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0marg_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2050\u001b[0;31m                 \u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1938\u001b[0m             \u001b[0mseen_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m             \u001b[0margument_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_strings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2484\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36m_check_value\u001b[0;34m(self, action, value)\u001b[0m\n\u001b[1;32m   2530\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid choice: %(value)r (choose from %(choices)s)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mArgumentError\u001b[0m: argument command: invalid choice: '/root/.local/share/jupyter/runtime/kernel-cc27bb8d-2c81-433a-ac13-bef2b5a9201e.json' (choose from 'compress', 'decompress')",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-324e0e799c96>\u001b[0m in \u001b[0;36m<cell line: 552>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-324e0e799c96>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1845\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1880\u001b[0m                 \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1881\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1882\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2605\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2606\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 2",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python lzw.py compress tests/small_text.txt tests/small_text_compressed.bin --stats-file compress_stats_small_text.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16IAqmH62hmi",
        "outputId": "a11394ba-fb05-4921-c835-3a50930d30d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo não encontrado -> [Errno 2] No such file or directory: 'tests/small_text.txt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/lzw.py\", line 552, in <module>\n",
            "    main()\n",
            "  File \"/content/lzw.py\", line 494, in main\n",
            "    compress(args.input_file, args.output_file, args.stats_file, args.max_bits)\n",
            "  File \"/content/lzw.py\", line 511, in compress\n",
            "    os.rename(compressed_file_name, output_file)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'compressed_small_text.bin' -> 'tests/small_text_compressed.bin'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python lzw.py decompress tests/small_text_compressed.bin tests/small_text_decompressed.txt --max-bits 16 --stats-file decompress_stats_small_text.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvkbAbZz6Xvw",
        "outputId": "ee0051b1-478e-4afc-8fb1-5e6bc6a61c31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found: tests/small_text_compressed.bin\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/lzw.py\", line 552, in <module>\n",
            "    main()\n",
            "  File \"/content/lzw.py\", line 496, in main\n",
            "    decompress(args.input_file, args.output_file, args.stats_file, args.max_bits)\n",
            "  File \"/content/lzw.py\", line 532, in decompress\n",
            "    trie_lzw.decompress(input_file, original_file_name, output_extension)\n",
            "  File \"/content/lzw.py\", line 388, in decompress\n",
            "    padding_size = int(compressed_data[:8], 2)\n",
            "ValueError: invalid literal for int() with base 2: ''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def are_files_identical(file1, file2):\n",
        "    \"\"\"\n",
        "    Compare two files byte by byte to check if they are identical.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file1, \"rb\") as f1, open(file2, \"rb\") as f2:\n",
        "            while True:\n",
        "                chunk1 = f1.read(4096)  # Read in chunks of 4 KB\n",
        "                chunk2 = f2.read(4096)\n",
        "                if chunk1 != chunk2:  # Compare the current chunks\n",
        "                    return False\n",
        "                if not chunk1:  # End of file reached\n",
        "                    return True\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "b5J-L0k_6s3A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rmdir /content/tests/compressed_tests\n",
        "!rm /content/tests/*\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRBpHOor___N",
        "outputId": "e1a59518-19c7-41df-a279-b3768ee67084"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmdir: failed to remove '/content/tests/compressed_tests': No such file or directory\n",
            "rm: cannot remove '/content/tests/*': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# Cria a pasta 'tests' se não existir\n",
        "folder_name = \"tests\"\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "\n",
        "# URLs das imagens para download\n",
        "urls = [\n",
        "    \"https://github.com/juliogdomingues/computacao_visual/raw/refs/heads/main/TP1/imagens/baboon.pgm\",\n",
        "    \"https://github.com/juliogdomingues/computacao_visual/raw/refs/heads/main/TP1/imagens/cameraman.pgm\",\n",
        "    \"https://github.com/juliogdomingues/computacao_visual/raw/refs/heads/main/TP1/imagens/lena512.pgm\",\n",
        "    \"https://github.com/juliogdomingues/computacao_visual/raw/refs/heads/main/TP1/imagens/unequal.pgm\"\n",
        "]\n",
        "\n",
        "# Baixa as imagens para a pasta 'tests'\n",
        "initial_files_set = set()\n",
        "for url in urls:\n",
        "    filename = url.split(\"/\")[-1]\n",
        "    destination_path = os.path.join(folder_name, filename)\n",
        "    print(f\"Baixando {filename}...\")\n",
        "    response = requests.get(url)\n",
        "    with open(destination_path, \"wb\") as file:\n",
        "        file.write(response.content)\n",
        "    print(f\"{filename} salvo com sucesso!\")\n",
        "    initial_files_set.add(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_EdnsNyUPo1",
        "outputId": "dc54aa08-be27-48e9-bbc3-2ab3fe6cebd9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baixando baboon.pgm...\n",
            "baboon.pgm salvo com sucesso!\n",
            "Baixando cameraman.pgm...\n",
            "cameraman.pgm salvo com sucesso!\n",
            "Baixando lena512.pgm...\n",
            "lena512.pgm salvo com sucesso!\n",
            "Baixando unequal.pgm...\n",
            "unequal.pgm salvo com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Após o processamento, deleta os arquivos não originais\n",
        "for file in os.listdir(folder_name):\n",
        "    if file not in initial_files_set:\n",
        "        os.remove(os.path.join(folder_name, file))\n",
        "\n",
        "print(f\"Arquivos restantes na pasta '{folder_name}': {os.listdir(folder_name)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfy2iKQNWB8r",
        "outputId": "17ec0908-5830-4158-8f8a-f2ef239fcded"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivos restantes na pasta 'tests': ['cameraman.pgm', 'unequal.pgm', 'baboon.pgm', 'lena512.pgm']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import filecmp\n",
        "\n",
        "# Configurações para melhor visualização dos gráficos\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "# Diretório onde os arquivos de teste estão localizados\n",
        "test_dir = 'tests'\n",
        "\n",
        "# Verifica se o diretório 'tests' existe\n",
        "if not os.path.exists(test_dir):\n",
        "    print(f\"O diretório '{test_dir}' não existe. Por favor, certifique-se de que os arquivos de teste estão na pasta '{test_dir}'.\")\n",
        "    exit(1)\n",
        "\n",
        "# Lista para armazenar os arquivos que precisam ser processados\n",
        "files_to_process = []\n",
        "\n",
        "# Extensões de arquivos a serem considerados\n",
        "valid_extensions = ['.txt', '.bmp', '.bin']\n",
        "\n",
        "# Percorrer todos os arquivos no diretório 'tests'\n",
        "for filename in os.listdir(test_dir):\n",
        "    file_path = os.path.join(test_dir, filename)\n",
        "    # Ignorar diretórios\n",
        "    if os.path.isdir(file_path):\n",
        "        continue\n",
        "    # Ignorar arquivos que já foram comprimidos ou descomprimidos\n",
        "    if filename.endswith('.lzw') or '_decompressed' in filename:\n",
        "        continue\n",
        "    # Ignorar arquivos de estatísticas ou outros arquivos não relevantes\n",
        "    if filename.endswith('_compress_stats.json') or filename.endswith('_decompress_stats.json'):\n",
        "        continue\n",
        "    # Verificar se a extensão é válida\n",
        "    _, ext = os.path.splitext(filename)\n",
        "    if ext.lower() in valid_extensions:\n",
        "        files_to_process.append(filename)\n",
        "    else:\n",
        "        print(f\"Arquivo com extensão não suportada encontrado e será ignorado: {filename}\")\n",
        "\n",
        "# Função para determinar o tipo de arquivo com base na extensão\n",
        "def get_file_type(extension):\n",
        "    if extension == '.txt':\n",
        "        return 'text'\n",
        "    elif extension == '.bmp':\n",
        "        return 'image'\n",
        "    elif extension == '.bin':\n",
        "        return 'binary'\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "# Listas para os dados de Compressão e Descompressão\n",
        "compression_data = []\n",
        "decompression_data = []\n",
        "\n",
        "# Automatizar a Compressão\n",
        "for filename in files_to_process:\n",
        "    input_file = os.path.join(test_dir, filename)\n",
        "    output_file = os.path.join(test_dir, f'{filename}.lzw')\n",
        "    stats_file = os.path.join(test_dir, f'{filename}_compress_stats.json')\n",
        "\n",
        "    # Verifica se o arquivo já foi comprimido\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\"Arquivo comprimido já existe: {output_file}. Pulando a compressão deste arquivo.\")\n",
        "        continue\n",
        "\n",
        "    command = [\n",
        "        'python', 'lzw.py', 'compress', input_file, output_file,\n",
        "        '--max-bits', '12', '--stats-file', stats_file\n",
        "    ]\n",
        "\n",
        "    print(f'Compressing {input_file}...')\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Erro ao comprimir {input_file}:\")\n",
        "        print(result.stderr)\n",
        "    else:\n",
        "        print(result.stdout)\n",
        "\n",
        "# Automatizar a Descompressão\n",
        "for filename in files_to_process:\n",
        "    input_file = os.path.join(test_dir, f'{filename}.lzw')\n",
        "    original_extension = os.path.splitext(filename)[1]\n",
        "    decompressed_filename = f'{os.path.splitext(filename)[0]}_decompressed{original_extension}'\n",
        "    output_file = os.path.join(test_dir, decompressed_filename)\n",
        "    stats_file = os.path.join(test_dir, f'{filename}_decompress_stats.json')\n",
        "\n",
        "    # Verifica se o arquivo comprimido existe\n",
        "    if not os.path.exists(input_file):\n",
        "        print(f\"Arquivo comprimido não encontrado: {input_file}. Pulando este arquivo.\")\n",
        "        continue\n",
        "\n",
        "    # Verifica se o arquivo já foi descomprimido\n",
        "    if os.path.exists(output_file):\n",
        "        print(f\"Arquivo descomprimido já existe: {output_file}. Pulando a descompressão deste arquivo.\")\n",
        "        continue\n",
        "\n",
        "    command = [\n",
        "        'python', 'lzw.py', 'decompress', input_file, output_file,\n",
        "        '--max-bits', '12', '--stats-file', stats_file\n",
        "    ]\n",
        "\n",
        "    print(f'Decompressing {input_file}...')\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Erro ao descomprimir {input_file}:\")\n",
        "        print(result.stderr)\n",
        "    else:\n",
        "        print(result.stdout)\n",
        "\n",
        "# Verificar os Arquivos Descomprimidos\n",
        "for filename in files_to_process:\n",
        "    original_file = os.path.join(test_dir, filename)\n",
        "    original_extension = os.path.splitext(filename)[1]\n",
        "    decompressed_filename = f'{os.path.splitext(filename)[0]}_decompressed{original_extension}'\n",
        "    decompressed_file = os.path.join(test_dir, decompressed_filename)\n",
        "\n",
        "    # Verifica se o arquivo descomprimido existe\n",
        "    if not os.path.exists(decompressed_file):\n",
        "        print(f\"Arquivo descomprimido não encontrado: {decompressed_file}. Pulando verificação deste arquivo.\")\n",
        "        continue\n",
        "\n",
        "    # Verifica se o arquivo já foi descomprimido corretamente\n",
        "    files_are_equal = filecmp.cmp(original_file, decompressed_file, shallow=False)\n",
        "    if files_are_equal:\n",
        "        print(f'{filename} descomprimido com sucesso.')\n",
        "    else:\n",
        "        print(f'Erro: {filename} foi descomprimido incorretamente.')\n",
        "\n",
        "# Coletar Estatísticas de Compressão e Descompressão\n",
        "for filename in files_to_process:\n",
        "    # Caminhos para os arquivos de estatísticas\n",
        "    compress_stats_file = os.path.join(test_dir, f'{filename}_compress_stats.json')\n",
        "    decompress_stats_file = os.path.join(test_dir, f'{filename}_decompress_stats.json')\n",
        "\n",
        "    # Determinar o tipo de arquivo com base na extensão\n",
        "    _, ext = os.path.splitext(filename)\n",
        "    ftype = get_file_type(ext.lower())\n",
        "\n",
        "    # Verifica se o arquivo de estatísticas de compressão existe\n",
        "    if os.path.exists(compress_stats_file):\n",
        "        with open(compress_stats_file, 'r') as f:\n",
        "            compress_stats = json.load(f)\n",
        "\n",
        "        # Calcular a taxa de compressão com base nos tamanhos dos arquivos\n",
        "        original_file = os.path.join(test_dir, filename)\n",
        "        compressed_file = os.path.join(test_dir, f'{filename}.lzw')\n",
        "        if os.path.exists(original_file) and os.path.exists(compressed_file):\n",
        "            original_size = os.path.getsize(original_file)\n",
        "            compressed_size = os.path.getsize(compressed_file)\n",
        "            compression_ratio = compressed_size / original_size if original_size != 0 else None\n",
        "        else:\n",
        "            compression_ratio = None\n",
        "\n",
        "        # Adicionar dados à lista de compressão\n",
        "        compression_data.append({\n",
        "            'File_Name': filename,\n",
        "            'File_Type': ftype,\n",
        "            'Compression_Ratio': compression_ratio,\n",
        "            'Dictionary_Size': compress_stats.get('dictionary_size_over_time', [])[-1] if compress_stats.get('dictionary_size_over_time') else None,\n",
        "            'Compression_Time(s)': compress_stats.get('execution_time', 0),\n",
        "            'Memory_Usage(KB)': compress_stats.get('memory_usage', 0)\n",
        "        })\n",
        "    else:\n",
        "        print(f\"Arquivo de estatísticas de compressão não encontrado: {compress_stats_file}\")\n",
        "\n",
        "    # Verifica se o arquivo de estatísticas de descompressão existe\n",
        "    if os.path.exists(decompress_stats_file):\n",
        "        with open(decompress_stats_file, 'r') as f:\n",
        "            decompress_stats = json.load(f)\n",
        "\n",
        "        # Adicionar dados à lista de descompressão\n",
        "        decompression_data.append({\n",
        "            'File_Name': filename,\n",
        "            'File_Type': ftype,\n",
        "            'Decompression_Time(s)': decompress_stats.get('execution_time', 0)\n",
        "        })\n",
        "    else:\n",
        "        print(f\"Arquivo de estatísticas de descompressão não encontrado: {decompress_stats_file}\")\n",
        "\n",
        "# Criar DataFrames\n",
        "compression_df = pd.DataFrame(compression_data)\n",
        "decompression_df = pd.DataFrame(decompression_data)\n",
        "\n",
        "# Exibir DataFrames\n",
        "print(\"Dados de Compressão:\")\n",
        "display(compression_df)\n",
        "\n",
        "print(\"Dados de Descompressão:\")\n",
        "display(decompression_df)\n",
        "\n",
        "# Plotar Tempo de Compressão por Arquivo\n",
        "if not compression_df.empty:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x='File_Name', y='Compression_Time(s)', hue='File_Type', data=compression_df)\n",
        "    plt.yscale('log')\n",
        "    plt.title('Tempo de Compressão por Arquivo (Escala Logarítmica)')\n",
        "    plt.xlabel('Arquivo')\n",
        "    plt.ylabel('Tempo de Compressão (log(segundos))')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title='Tipo de Arquivo')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Nenhum dado de compressão disponível para plotar.\")\n",
        "\n",
        "# Plotar Tempo de Descompressão por Arquivo\n",
        "if not decompression_df.empty:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x='File_Name', y='Decompression_Time(s)', hue='File_Type', data=decompression_df)\n",
        "    plt.yscale('log')\n",
        "    plt.title('Tempo de Descompressão por Arquivo (Escala Logarítmica)')\n",
        "    plt.xlabel('Arquivo')\n",
        "    plt.ylabel('Tempo de Descompressão (log(segundos))')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title='Tipo de Arquivo')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Nenhum dado de descompressão disponível para plotar.\")\n",
        "\n",
        "# Plotar Taxa de Compressão por Arquivo\n",
        "if not compression_df.empty:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x='File_Name', y='Compression_Ratio', hue='File_Type', data=compression_df)\n",
        "    plt.title('Taxa de Compressão por Arquivo')\n",
        "    plt.xlabel('Arquivo')\n",
        "    plt.ylabel('Taxa de Compressão (Comprimido / Original)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title='Tipo de Arquivo')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Nenhum dado de compressão disponível para plotar.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Fh2VCk847gRb",
        "outputId": "e96a137a-bc5d-4fe0-b76c-c6e8b48f3ddd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo com extensão não suportada encontrado e será ignorado: cameraman.pgm\n",
            "Arquivo com extensão não suportada encontrado e será ignorado: unequal.pgm\n",
            "Arquivo com extensão não suportada encontrado e será ignorado: baboon.pgm\n",
            "Arquivo com extensão não suportada encontrado e será ignorado: lena512.pgm\n",
            "Dados de Compressão:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2dd98aa6-6abb-4bdc-b726-2926ec7ba065\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dd98aa6-6abb-4bdc-b726-2926ec7ba065')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2dd98aa6-6abb-4bdc-b726-2926ec7ba065 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2dd98aa6-6abb-4bdc-b726-2926ec7ba065');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_10140940-5784-4959-83fb-469e1f04a806\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('compression_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_10140940-5784-4959-83fb-469e1f04a806 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('compression_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "compression_df",
              "summary": "{\n  \"name\": \"compression_df\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados de Descompressão:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4bb10d7c-9c9c-4684-8c63-8c2321a999d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4bb10d7c-9c9c-4684-8c63-8c2321a999d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4bb10d7c-9c9c-4684-8c63-8c2321a999d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4bb10d7c-9c9c-4684-8c63-8c2321a999d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_8a311b92-f01c-4030-9dfd-61b01847b1b8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('decompression_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8a311b92-f01c-4030-9dfd-61b01847b1b8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('decompression_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "decompression_df",
              "summary": "{\n  \"name\": \"decompression_df\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nenhum dado de compressão disponível para plotar.\n",
            "Nenhum dado de descompressão disponível para plotar.\n",
            "Nenhum dado de compressão disponível para plotar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RncQPZ8lCZjQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fazendo a compressão e a descompressão de arquivos usando a classe TrieLZW:"
      ],
      "metadata": {
        "id": "mmZHM1wtffn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Função temporária para verificar se dois arquivos são iguais:"
      ],
      "metadata": {
        "id": "1xCgIMdnIFn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def are_files_identical(file1, file2):\n",
        "    \"\"\"\n",
        "    Compare two files byte by byte to check if they are identical.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file1, \"rb\") as f1, open(file2, \"rb\") as f2:\n",
        "            while True:\n",
        "                chunk1 = f1.read(4096)  # Read in chunks of 4 KB\n",
        "                chunk2 = f2.read(4096)\n",
        "                if chunk1 != chunk2:  # Compare the current chunks\n",
        "                    return False\n",
        "                if not chunk1:  # End of file reached\n",
        "                    return True\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "FY9kGlKUIFIz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 1 (arquivo de texto)"
      ],
      "metadata": {
        "id": "j1DNUBiQFIEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerando artificialmente um texto para teste:"
      ],
      "metadata": {
        "id": "N3gY71UFGNqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Generate the random text\n",
        "input_data = ''.join(random.choices(\"abcd\", k=100000))\n",
        "\n",
        "#input_data = 'geekific-geekific'\n",
        "\n",
        "# Specify the file path\n",
        "file_path = \"test_text.txt\"\n",
        "\n",
        "# Save the text to a .txt file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(input_data)"
      ],
      "metadata": {
        "id": "FDykAeJ8GoZI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando a compressão e a descompressão em sequência:"
      ],
      "metadata": {
        "id": "W2gy7nClHEf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teste_trie_lzw = TrieLZW()\n",
        "\n",
        "file_to_be_compressed = \"test_text.txt\"\n",
        "\n",
        "[file_name, file_extension] = teste_trie_lzw.compress(file_to_be_compressed)\n",
        "\n",
        "compressed_file = f\"compressed_{file_name}.bin\"\n",
        "\n",
        "teste_trie_lzw.decompress(compressed_file, file_name, file_extension)"
      ],
      "metadata": {
        "id": "_VDMpzrHZvqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando o tamanho dos arquivos iniciais e finais:"
      ],
      "metadata": {
        "id": "vq-qVz1JHND5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_file_size = os.path.getsize(file_to_be_compressed)\n",
        "compressed_file_size = os.path.getsize(compressed_file)\n",
        "\n",
        "print(f\"Tamanho do arquivo original: {original_file_size} bytes.\")\n",
        "print(f\"Tamanho do arquivo comprimido: {compressed_file_size} bytes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVQ17h5hHNam",
        "outputId": "5e8be013-d43d-4bfc-97df-498aa4db0f9e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do arquivo original: 100000 bytes.\n",
            "Tamanho do arquivo comprimido: 28406 bytes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se os arquivos são equivalentes:"
      ],
      "metadata": {
        "id": "xxaprA7qIKI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt_file1 = file_to_be_compressed\n",
        "txt_file2 = f\"decompressed_{file_to_be_compressed}\"\n",
        "print(txt_file1)\n",
        "print(txt_file2)\n",
        "print(f\"Os arquivos .txt são iguais? {are_files_identical(txt_file1, txt_file2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPXmewVOH3zY",
        "outputId": "392177a4-9d10-4183-c5cf-a141bf00e0d1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_text.txt\n",
            "decompressed_test_text.txt\n",
            "Os arquivos .txt são iguais? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linha de comando"
      ],
      "metadata": {
        "id": "Ou8g-7Pab7hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compressão\n",
        "!python lzw.py compress test_text.txt compressed_test_text.bin --stats-file compress_stats_test_text.json\n",
        "\n",
        "# Calcula e imprime os tamanhos dos arquivos original e comprimido\n",
        "import os\n",
        "original_file_size = os.path.getsize(\"test_text.txt\")\n",
        "compressed_file_size = os.path.getsize(\"compressed_test_text.bin\")\n",
        "print(f\"Tamanho do arquivo original: {original_file_size} bytes.\")\n",
        "print(f\"Tamanho do arquivo comprimido: {compressed_file_size} bytes.\")"
      ],
      "metadata": {
        "id": "bXAdanNlb2pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descompressão\n",
        "!python lzw.py decompress compressed_test_text.bin decompressed_test_text.txt --max-bits 16 --stats-file decompress_stats_test_text.json\n",
        "\n",
        "# Verifica se os arquivos original e descomprimido são iguais\n",
        "def are_files_identical(file1, file2):\n",
        "    with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
        "        return f1.read() == f2.read()\n",
        "\n",
        "txt_file1 = \"test_text.txt\"\n",
        "txt_file2 = \"decompressed_test_text.txt\"\n",
        "print(f\"Os arquivos .txt são iguais? {are_files_identical(txt_file1, txt_file2)}\")"
      ],
      "metadata": {
        "id": "9RGrUBC1b_s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo 2 (arquivo de imagem)"
      ],
      "metadata": {
        "id": "DmRmH2ByF57b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gerando artificialmente uma imagem para teste:"
      ],
      "metadata": {
        "id": "xXx45HefE6Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Create a new monochrome (mode '1') image with 10x10 pixels\n",
        "width, height = 1000, 1000\n",
        "image = Image.new(\"1\", (width, height))  # Mode \"1\" means 1-bit pixels (monochrome)\n",
        "\n",
        "# Set some pixels to black (1 = white, 0 = black)\n",
        "pixels = image.load()\n",
        "for x in range(width):\n",
        "    for y in range(height):\n",
        "        if (x + y) % 2 == 0:  # Example pattern: checkerboard\n",
        "            pixels[x, y] = 0  # Black pixel\n",
        "        else:\n",
        "            pixels[x, y] = 1  # White pixel\n",
        "\n",
        "# Save the image as a BMP file\n",
        "image.save(\"monochrome_test_image.bmp\")"
      ],
      "metadata": {
        "id": "xn3RDWTVETTH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando a compressão e a descompressão em sequência:"
      ],
      "metadata": {
        "id": "euSnTsx0GDau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teste_trie_lzw = TrieLZW()\n",
        "\n",
        "file_to_be_compressed = \"monochrome_test_image.bmp\"\n",
        "\n",
        "[file_name, file_extension] = teste_trie_lzw.compress(file_to_be_compressed)\n",
        "\n",
        "compressed_file = f\"compressed_{file_name}.bin\"\n",
        "\n",
        "teste_trie_lzw.decompress(compressed_file, file_name, file_extension)"
      ],
      "metadata": {
        "id": "4jAYNs6mfjyT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando o tamanho dos arquivos iniciais e finais:"
      ],
      "metadata": {
        "id": "c_QpZq3kDbtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_file_size = os.path.getsize(file_to_be_compressed)\n",
        "compressed_file_size = os.path.getsize(compressed_file)\n",
        "\n",
        "print(f\"Tamanho do arquivo original: {original_file_size} bytes.\")\n",
        "print(f\"Tamanho do arquivo comprimido: {compressed_file_size} bytes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHQ4te_yCXLH",
        "outputId": "55f63a12-d559-4233-a77b-fa79d8cf2fbb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do arquivo original: 128062 bytes.\n",
            "Tamanho do arquivo comprimido: 2672 bytes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando se os arquivos são equivalentes:"
      ],
      "metadata": {
        "id": "NMYnnNwsISgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bmp_file1 = file_to_be_compressed\n",
        "bmp_file2 = f\"decompressed_{file_to_be_compressed}\"\n",
        "\n",
        "print(f\"Os arquivos .bmp são iguais? {are_files_identical(bmp_file1, bmp_file2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUwbzZT6IPsG",
        "outputId": "fb58c09d-fd0a-4bca-e2bd-19e6573fb729"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Os arquivos .bmp são iguais? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linha de comando"
      ],
      "metadata": {
        "id": "1xskF1yObvhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compressão\n",
        "!python lzw.py compress monochrome_test_image.bmp compressed_monochrome_test_image.bin --stats-file compress_stats_monochrome_image.json\n",
        "\n",
        "# Calcula e imprime os tamanhos dos arquivos original e comprimido\n",
        "import os\n",
        "original_file_size = os.path.getsize(\"monochrome_test_image.bmp\")\n",
        "compressed_file_size = os.path.getsize(\"compressed_monochrome_test_image.bin\")\n",
        "print(f\"Tamanho do arquivo original: {original_file_size} bytes.\")\n",
        "print(f\"Tamanho do arquivo comprimido: {compressed_file_size} bytes.\")"
      ],
      "metadata": {
        "id": "txktSiGnbugZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descompressão\n",
        "!python lzw.py decompress compressed_monochrome_test_image.bin decompressed_monochrome_test_image.bmp --max-bits 16 --stats-file decompress_stats_monochrome_image.json\n",
        "\n",
        "# Verifica se os arquivos BMP são iguais\n",
        "def are_files_identical(file1, file2):\n",
        "    with open(file1, 'rb') as f1, open(file2, 'rb') as f2:  # Lê os arquivos como binários\n",
        "        return f1.read() == f2.read()\n",
        "\n",
        "bmp_file1 = \"monochrome_test_image.bmp\"\n",
        "bmp_file2 = \"decompressed_monochrome_test_image.bmp\"\n",
        "print(f\"Os arquivos .bmp são iguais? {are_files_identical(bmp_file1, bmp_file2)}\")"
      ],
      "metadata": {
        "id": "GZevuxyJbvF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seção provisória para debug"
      ],
      "metadata": {
        "id": "W0AHGnxlDQKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import struct\n",
        "\n",
        "def int_to_8bit_binary(number):\n",
        "  return format(number, '08b')\n",
        "\n",
        "def remove_leading_zeros(binary_str):\n",
        "  return binary_str.lstrip('0') or '0'\n",
        "\n",
        "class LZW:\n",
        "    def __init__(self):\n",
        "        self.max_table_size = 4096\n",
        "\n",
        "    def compress(self, input_data):\n",
        "        dictionary = {chr(i): i for i in range(256)}\n",
        "        string = \"\"\n",
        "        compressed_data = []\n",
        "\n",
        "        for symbol in input_data:\n",
        "            string_plus_symbol = string + symbol\n",
        "            if string_plus_symbol in dictionary:\n",
        "                string = string_plus_symbol\n",
        "            else:\n",
        "                compressed_data.append(dictionary[string])\n",
        "                if len(dictionary) < self.max_table_size:\n",
        "                    dictionary[string_plus_symbol] = len(dictionary)\n",
        "                string = symbol\n",
        "\n",
        "        if string in dictionary:\n",
        "            compressed_data.append(dictionary[string])\n",
        "\n",
        "        return compressed_data\n",
        "\n",
        "    def decompress(self, compressed_data):\n",
        "        dictionary = {chr(i): i for i in range(256)}\n",
        "        string = chr(compressed_data.pop(0))\n",
        "        decompressed_data = [string]\n",
        "\n",
        "        for k in compressed_data:\n",
        "            print(k)\n",
        "            if k in dictionary:\n",
        "                entry = dictionary[k]\n",
        "            elif k == len(dictionary):\n",
        "                entry = string + string[0]\n",
        "            else:\n",
        "                raise ValueError(\"Erro na compressão k: %s\" % k)\n",
        "\n",
        "            decompressed_data.append(entry)\n",
        "\n",
        "            if len(dictionary) < self.max_table_size:\n",
        "                dictionary[len(dictionary)] = string + entry[0]\n",
        "\n",
        "            string = entry\n",
        "\n",
        "        return ''.join(decompressed_data)"
      ],
      "metadata": {
        "id": "dJYdN1_XzR4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "import random\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    lzw = LZW()\n",
        "\n",
        "    input_data = ''.join(random.choices(\"ab\", k=1000))\n",
        "\n",
        "    input_data = 'geekific-geekific'\n",
        "\n",
        "    with open(\"input.txt\", 'w') as file:\n",
        "      file.write(input_data)\n",
        "\n",
        "    with open(\"input.txt\", \"r\") as file:\n",
        "      input_data = file.read()\n",
        "\n",
        "    with open('input.txt', 'rb') as file:\n",
        "      input_data_2 = file.read()\n",
        "      input_data_2 = list(input_data_2)\n",
        "\n",
        "    compressed_data = lzw.compress(input_data)\n",
        "    #compressed_data_trie = lzw.compress_trie(input_data_2)\n",
        "    #integer_compressed_data_trie = [int(binary, 2) for binary in compressed_data_trie]\n",
        "\n",
        "    #print(\"A compressão ficou igual!\") if compressed_data == integer_compressed_data_trie else print(\"A compressão ficou diferente!\")\n",
        "    print(\"Arquivo comprimido (dict):\", compressed_data)\n",
        "    #print(\"Arquivo comprimido (trie):\", integer_compressed_data_trie)\n",
        "    #print(\"Arquivo comprimido original (trie):\", compressed_data_trie)\n",
        "\n",
        "    with open(\"text_compressed_result.txt\", 'w') as file:\n",
        "      final_compressed_string = ''.join(compressed_data_trie)\n",
        "      file.write(final_compressed_string)\n",
        "\n",
        "    with open(\"binary_compressed_result.bin\", 'wb') as file:\n",
        "      final_compressed_string = ''.join(compressed_data_trie)\n",
        "\n",
        "      padding_size = (8 - len(final_compressed_string) % 8) % 8\n",
        "      final_compressed_string = '0' * padding_size + final_compressed_string\n",
        "\n",
        "      file.write(bytes([padding_size]))\n",
        "\n",
        "      bits = []\n",
        "      for char in final_compressed_string:\n",
        "          bits.append(1 if char == '1' else 0)\n",
        "\n",
        "      byte = 0\n",
        "      bit_count = 0\n",
        "      for bit in bits:\n",
        "          byte = (byte << 1) | bit\n",
        "          bit_count += 1\n",
        "\n",
        "          if bit_count == 8:\n",
        "              file.write(bytes([byte]))\n",
        "              byte = 0\n",
        "              bit_count = 0\n",
        "\n",
        "    size_file1 = os.path.getsize(\"input.txt\")\n",
        "    size_file2 = os.path.getsize(\"binary_compressed_result.bin\")\n",
        "\n",
        "    with open(\"binary_compressed_result.bin\", 'rb') as file:\n",
        "      padding_size = ord(file.read(1))\n",
        "\n",
        "      data = file.read()\n",
        "\n",
        "      binary_string = ''.join(format(byte, '08b') for byte in data)\n",
        "\n",
        "      binary_string = binary_string[padding_size:]\n",
        "\n",
        "    result = lzw.decompress_trie(binary_string)\n",
        "\n",
        "    print(\" O resultado antes da compressão é: \" + input_data)\n",
        "    print(\"O resultado após a descompressão é: \" + result)\n",
        "    print(f\"Tamanho do arquivo original: {size_file1} bytes\")\n",
        "    print(f\"Tamanho do arquivo comprimido: {size_file2} bytes\")\n",
        "    print(\"O LZW foi bem-sucedido!\") if result == input_data else print(\"O LZW não foi bem-sucedido!\")\n",
        "\n",
        "    with open(\"compressed_binary.txt\", \"w\") as file:\n",
        "        binary_data = ' '.join(format(data, '012b') for data in compressed_data)\n",
        "        file.write(binary_data)\n",
        "\n",
        "    decompressed_data = lzw.decompress(compressed_data)\n",
        "    print(\"Arquivo descomprimido:\", decompressed_data)\n",
        "\n",
        "    with open(\"decompressed.txt\", \"w\") as file:\n",
        "        file.write(decompressed_data)\n",
        "    '''"
      ],
      "metadata": {
        "id": "5YRTsawOvp5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import os\n",
        "from IPython.display import Image\n",
        "from random import choice\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "trie = CompactTrie()\n",
        "\n",
        "k = bin(0)[2:]\n",
        "v = format(0, '08b')\n",
        "\n",
        "trie.insert(k, v)\n",
        "\n",
        "file_path = \"interactive_trie.png\"\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "    print(f\"{file_path} has been deleted.\")\n",
        "else:\n",
        "    print(f\"{file_path} does not exist.\")\n",
        "trie.visualize(\"interactive_trie\")\n",
        "display(Image(filename=\"interactive_trie.png\"))\n",
        "'''"
      ],
      "metadata": {
        "id": "esCMZ8v7RSON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import Image\n",
        "from random import choice\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "trie = CompactTrie()\n",
        "global_counter = 0\n",
        "delete_input = widgets.Text(description=\"Delete:\")\n",
        "delete_button = widgets.Button(description=\"Delete String\")\n",
        "\n",
        "def reset_trie(_):\n",
        "    global trie, global_counter\n",
        "    trie = CompactTrie()\n",
        "    global_counter = 0\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    auto_button = widgets.Button(description=\"Auto\")\n",
        "    auto_button.on_click(random_insert)\n",
        "    display(auto_button)\n",
        "\n",
        "def random_insert(_):\n",
        "    global global_counter\n",
        "    global_counter += 1\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    iterate_button = widgets.Button(description=\"Next Iteration\")\n",
        "    iterate_button.on_click(random_insert)\n",
        "    display(iterate_button)\n",
        "\n",
        "    delete_button.on_click(delete_string)\n",
        "    display(delete_input)\n",
        "    display(delete_button)\n",
        "\n",
        "    reset_button = widgets.Button(description=\"Reset Trie\")\n",
        "    reset_button.on_click(reset_trie)\n",
        "    display(reset_button)\n",
        "\n",
        "    new_node_string = ''.join(choice(['a', 'b']) for _ in range(6))\n",
        "    print(f\"Generated string: {new_node_string}\")\n",
        "\n",
        "    new_binary_string = ''.join('0' if char == 'a' else '1' for char in new_node_string)\n",
        "\n",
        "    trie.insert(new_binary_string, global_counter)\n",
        "\n",
        "    file_path = \"interactive_trie.png\"\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        print(f\"{file_path} has been deleted.\")\n",
        "    else:\n",
        "        print(f\"{file_path} does not exist.\")\n",
        "\n",
        "    trie.visualize(\"interactive_trie\")\n",
        "\n",
        "    display(Image(filename=\"interactive_trie.png\"))\n",
        "\n",
        "def delete_string(_):\n",
        "    global delete_input\n",
        "    binary_string = delete_input.value.strip()\n",
        "    new_binary_string = ''.join('0' if char == 'a' else '1' for char in binary_string)\n",
        "    trie.delete_key(new_binary_string)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    iterate_button = widgets.Button(description=\"Next Iteration\")\n",
        "    iterate_button.on_click(random_insert)\n",
        "    display(iterate_button)\n",
        "\n",
        "    delete_button.on_click(delete_string)\n",
        "    display(delete_input)\n",
        "    display(delete_button)\n",
        "\n",
        "    reset_button = widgets.Button(description=\"Reset Trie\")\n",
        "    reset_button.on_click(reset_trie)\n",
        "    display(reset_button)\n",
        "\n",
        "    file_path = \"interactive_trie.png\"\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        os.remove(file_path)\n",
        "        print(f\"{file_path} has been deleted.\")\n",
        "    else:\n",
        "        print(f\"{file_path} does not exist.\")\n",
        "\n",
        "    trie.visualize(\"interactive_trie\")\n",
        "\n",
        "    display(Image(filename=\"interactive_trie.png\"))\n",
        "\n",
        "auto_button = widgets.Button(description=\"Auto\")\n",
        "auto_button.on_click(random_insert)\n",
        "display(auto_button)"
      ],
      "metadata": {
        "id": "kvvKGx9OODL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I5e007m7sk_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "def process_directory(input_directory: str, output_stats_file: str, compressed_dir: str):\n",
        "    stats = {}\n",
        "    lzw = TrieLZW()  # Instancia a classe de compressão\n",
        "\n",
        "    # Garante que o diretório para arquivos comprimidos existe\n",
        "    os.makedirs(compressed_dir, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(input_directory):\n",
        "        filepath = os.path.join(input_directory, filename)\n",
        "\n",
        "        if os.path.isfile(filepath):\n",
        "            print(f\"Processing file: {filename}\")\n",
        "\n",
        "            try:\n",
        "                # Chama o método de compressão da classe TrieLZW\n",
        "                file_name, file_extension = lzw.compress(filepath)\n",
        "\n",
        "                # Caminho original gerado pelo método compress\n",
        "                compressed_file = f\"compressed_{file_name}.bin\"\n",
        "\n",
        "                # Se o arquivo já foi salvo em compressed_dir, não é necessário mover\n",
        "                original_compressed_path = os.path.join(os.getcwd(), compressed_file)\n",
        "                if not os.path.exists(original_compressed_path):\n",
        "                    original_compressed_path = os.path.join(compressed_dir, compressed_file)\n",
        "\n",
        "                # Verifica se o arquivo existe e move para o diretório correto\n",
        "                if os.path.exists(original_compressed_path):\n",
        "                    new_compressed_path = os.path.join(compressed_dir, compressed_file)\n",
        "                    os.rename(original_compressed_path, new_compressed_path)\n",
        "                else:\n",
        "                    print(f\"Compressed file not found: {compressed_file}\")\n",
        "\n",
        "                # Armazena as estatísticas para o arquivo processado\n",
        "                stats[filename] = {\n",
        "                    \"compression_ratio_over_time\": lzw.stats['compression_ratio_over_time'],\n",
        "                    \"dictionary_size_over_time\": lzw.stats['dictionary_size_over_time'],\n",
        "                    \"execution_time\": lzw.stats['execution_time'],\n",
        "                    \"memory_usage\": lzw.stats['memory_usage']\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "    # Salva as estatísticas em um arquivo JSON\n",
        "    with open(output_stats_file, 'w', encoding='utf-8') as stats_file:\n",
        "        json.dump(stats, stats_file, indent=4)\n",
        "\n",
        "    print(f\"Statistics saved to {output_stats_file}\")\n",
        "\n",
        "# Configuração do diretório de entrada e saída\n",
        "input_directory = \"tests\"  # Substitua pelo caminho do seu diretório de testes\n",
        "compressed_directory = \"compressed_tests\"  # Diretório para salvar os arquivos comprimidos\n",
        "output_file = \"statistics.json\"\n",
        "\n",
        "process_directory(input_directory, output_file, compressed_directory)"
      ],
      "metadata": {
        "id": "boTJPuuSz1KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJPoqrrOz8WH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}